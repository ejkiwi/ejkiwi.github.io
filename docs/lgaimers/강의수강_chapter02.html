<!DOCTYPE html> <html><head>
		<title>강의수강_chapter02</title>
		<base href="../">
		<meta id="root-path" root-path="../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="ejkiwi.github.io - 강의수강_chapter02">
		<meta property="og:title" content="강의수강_chapter02">
		<meta property="og:description" content="ejkiwi.github.io - 강의수강_chapter02">
		<meta property="og:type" content="website">
		<meta property="og:url" content="https://ejkiwi.github.io/lgaimers/강의수강_chapter02.html">
		<meta property="og:image" content="undefined">
		<meta property="og:site_name" content="ejkiwi.github.io">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://ejkiwi.github.io/lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-light show-inline-title show-ribbon mk-readable-line mk-folder-lines mk-spaces-enabled mk-inline-context-enabled mk-flow-seamless"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..." style="border-radius:10px; border-width: 0px;"><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles"></style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="01"><p dir="auto">01</p></h1><div class="el-h1 heading-wrapper"><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="머신러닝과 딥러닝" dir="auto" class="heading" id="머신러닝과_딥러닝"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>머신러닝과 딥러닝</h3><div class="heading-children"><div class="el-p"><p dir="auto">머신러닝 : 데이터로부터 패턴 파악, 학습</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>알고리즘이 학습과정에서의 피드백 받는 방식
<ul>
<li data-line="1" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>supervised
<ul>
<li data-line="2" dir="auto">data + labels</li>
<li data-line="3" dir="auto">overfitting 가능성</li>
<li data-line="4" dir="auto">regression / classification</li>
</ul>
</li>
<li data-line="5" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>semisupervised / selfsupervised
<ul>
<li data-line="6" dir="auto">pseudo-labeled data</li>
</ul>
</li>
<li data-line="7" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>unsupervised
<ul>
<li data-line="8" dir="auto">unlabeled data</li>
</ul>
</li>
<li data-line="9" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>reinforcement
<ul>
<li data-line="10" dir="auto">agent의 action -&gt; state + reward ( reward system )</li>
<li data-line="11" dir="auto">trial and error<br>
딥러닝 : 하나 이상의 hidden layer를 갖고 있는 neural network</li>
</ul>
</li>
</ul>
</li>
<li data-line="13" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>neural network : 행렬의 모임 ( feature들의 weight 만큼의 정보가 담겨있는 유의미한 행렬임 )
<ul>
<li data-line="14" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>이 neural network를 학습한다는 것 : 각 node를 연결하는 weight의 값을 얼마로 할당해줄까? 에 대한 것들을 찾아가는 과정임
<ul>
<li data-line="15" dir="auto">loss -&gt; backpropagation으로 계속 업데이트해나가며 찾아감</li>
</ul>
</li>
</ul>
</li>
<li data-line="16" dir="auto">단일 neural network -&gt; 이건 아무리 딥하게 쌓아도 그냥 linear한 함수가 되는거임 -&gt; non linear fuction이 꼬옥 필요한 이유. 비선형성이 추가되어야함 ( xor 문제 생각해보기! )</li>
<li data-line="17" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>일반적인 neural network ( 비선형성이 추가됨 )
<ul>
<li data-line="18" dir="auto">fully connected networkt : 앞 모든 뉴런들 - 다음 뉴런 모두 연결</li>
</ul>
</li>
<li data-line="19" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>그럼 prediction에서는?
<ul>
<li data-line="20" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>우리가 하자고 했던 task에 맞추어 결과를 뽑아낼 수 있어야 함 - 확률 분포를 뽑아내야 함.
<ul>
<li data-line="21" dir="auto">softmax layer</li>
</ul>
</li>
<li data-line="22" dir="auto">prediction을 통해 loss를 구하고, backpropagation 수행</li>
</ul>
</li>
</ul></div></div></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="02" dir="auto" class="heading" id="02">02</h1><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="자연어 처리 모델" dir="auto" class="heading" id="자연어_처리_모델"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>자연어 처리 모델</h3><div class="heading-children"><div class="el-p"><p dir="auto">tokenization</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>vocab size
<ul>
<li data-line="1" dir="auto">too big : 너무 많은 계산량</li>
<li data-line="2" dir="auto">too small : 너무 많은 단어가 unk token이 되는것<br>
word embedding</li>
</ul>
</li>
<li data-line="4" dir="auto">bag of words : 고냥 제일 단순한 단어 매칭임 (one hot vector같은 고)</li>
<li data-line="5" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>word2vec : 특정 단어A의 임베딩을 위해 주변 단어들을 이용해서 A를 예측하도록 하는 pseudo task를 정의하여 학습시킨 임베딩 방식
<ul>
<li data-line="6" dir="auto">cbow : 주변 단어들을 통해 특정 단어를 예측하는 방식으로 vector값 업데이트</li>
<li data-line="7" dir="auto">skip gram : 특정 단어를 통해 주변 단어를 예측하는 방식으로 vector값 업데이트</li>
<li data-line="8" dir="auto">위와 같은 방식들의 최종(마지막) hidden layer가 각 단어의 word vector묶음마냥 표현이 되는 것 -&gt; word embedding vector<br>
language model ( lstm 까지..! )<br>
language model의 학습 단어 시퀀스에서 다음 단어의 확률 분포를 뽑는 과정</li>
</ul>
</li>
<li data-line="11" dir="auto">fixed language model : windows가 정해진(문맥의 단어 개수가 정해진 상황) 상황이 가정된 모델 -&gt; 전체 문맥을 봐야하는데 이러면 어떡함?</li>
<li data-line="12" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>rnn : sequential data에 너무나도 자연스러운 형태임 이전 내용 계속 누적. 하나의 weight를 계속 공유하기 때문에 이러한 것이 가능함. 그러나 computation측면에서 많은 단점.
<ul>
<li data-line="13" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>매 step(시퀀스에서 단어를 하나하나 가져올 때마다)마다 loss 계산, gradient 계산 하는 과정
<ul>
<li data-line="14" dir="auto">이 때 이전 결과를 다음 입력으로 넣을수도,</li>
<li data-line="15" dir="auto">정답 자체를 다음 입력으로 넣을수도 있음.</li>
</ul>
</li>
</ul>
</li>
<li data-line="16" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>lstm rnn : rnn에 gate, cell추가됨
<ul>
<li data-line="17" dir="auto">forget gate : 얼마나 잊을것인가? -&gt; 이전 정보를 얼마 만큼만 보존하고 반영할 것인지를 -&gt; 이전 정보의 중요도 결정</li>
<li data-line="18" dir="auto">input gate : 얼마나 입력할것인가? -&gt; 새로운 내용을 얼마만큼 반영할 것인지를 -&gt; 새 값의 가중치 결정</li>
<li data-line="19" dir="auto">output gate : cell state에서 얼마나 출력할것인가? ( hidden sate 결정 )</li>
<li data-line="20" dir="auto">cell state : 장기 기억 저장 벡터 값</li>
<li data-line="21" dir="auto"><code>C_t = (forget gate × C_{t-1}) + (input gate × C̃_t)</code> : forget gate, input gate는 각각 순차적인 계산이 아니라 두 gate의 결과를 병렬로 계산 후 더하는 것</li>
</ul>
</li>
</ul></div></div></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="03" dir="auto" class="heading" id="03">03</h1><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="transformer와 attention" dir="auto" class="heading" id="transformer와_attention"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>transformer와 attention</h3><div class="heading-children"><div class="el-p"><p dir="auto">기존 seq2seq (encoder-decoder) 구조 모델</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">encoder rnn : input 문장 요약 / 이해</li>
<li data-line="1" dir="auto">decoder rnn : encoder layer를 거친 마지막 hidden state를 다시 decoder rnn 입력으로 넣어, 순차으로 단어 예측</li>
<li data-line="2" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>rnn이 가지는 기존 단점이 여전히 존재. encoder의 last hidden state만을 가지고 decoder의 입력으로 들어가기 때문에, encoder에서의 최근 정보만 강하게 기억, 초반 부분의 내용은 많이 잊게 됨
<ul>
<li data-line="3" dir="auto">그럼 초기~최근 으로 갈수록 더 많이 기억하게 되는 구조를 사용하지 말아보자</li>
<li data-line="4" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>중요한 부분에만 집중하도록 해보는 건? -&gt;attention
<ul>
<li data-line="5" dir="auto">encoder의 last hidden state를 쓰는 것이 아니라, context vector라는 것을 만들어서 사용해보기</li>
<li data-line="6" dir="auto">context vector : encoder의 hidden state -&gt; attention weight 계산 -&gt; weighted sum - normalization (softmax)</li>
<li data-line="7" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>attention weight
<ul>
<li data-line="8" dir="auto">encoder의 hidden state와 decoder의 hidden state의 연관성을 보자</li>
<li data-line="9" dir="auto">여기서의 연관성 =&gt; dot product를 계산 후 socre 뽑아내기</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul></div><div class="el-p"><p dir="auto">rnn &lt;-&gt; transformer</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">rnn의 기존 문제점 : 한 번에 많은 sequence를 처리하기 힘들다, 병렬 처리가 불가능한 구조, 장기 의존성 문제</li>
<li data-line="1" dir="auto">transformer : rnn과는 완전히 새롭고 다른 구조 -&gt; attention mechanism만 이용해서 만들어진 구조, 병렬 처리 가능, 애초에 모든 단어들이 fully connected하게 연결되어 처리됨</li>
</ul></div><div class="el-p"><p dir="auto">self attention</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">스스로 각 문장 안에서 각 단어끼리의 관계성(attention weight) 계산</li>
<li data-line="1" dir="auto">계속 단어간의 표현(representation)의 상호작용을 일으키게 됨</li>
<li data-line="2" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>query key value
<ul>
<li data-line="3" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>단어의 representation을 projection 하여 query key value를 만드는 것에서 부터 시작함
<ul>
<li data-line="4" dir="auto">기존 단어들에서부터 그대로 사영하여 query 하나를 만들어두고</li>
<li data-line="5" dir="auto">기존 단어들에서부터 그대로 사영하여 key 하나를 만들어두고</li>
<li data-line="6" dir="auto">기존 단어들에서부터 그대로 사영하여 value 하나를 만들어둠</li>
<li data-line="7" dir="auto">결국 이 query key value는 하나의 입력에서부터 동일하게 나온 것들임 -&gt; "self" attention</li>
</ul>
</li>
<li data-line="8" dir="auto">query와 key의 dot product 계산 -&gt; 확률 형태로 normalization : 문장 속 각 단어들간의 관계 (중요성)을 뽑아냄</li>
<li data-line="9" dir="auto">앞에서 뽑아낸 중요성을 value vector와 곱함(weighted sum) -&gt;  단어의 새로운 representation을 만들기 =&gt; "self attention"</li>
</ul>
</li>
</ul></div><div class="el-p"><p dir="auto">positional embedding<br>
rnn은 시퀀스를 처리할 때 단어 하나하나를 순차적으로 처리 -&gt; 시간의 순서가 반영됨<br>
transformer는 병렬 처리되기 때문에 순차적(시간적)인 개념이 반영되지 않음. -&gt; positional embedding 사용</p></div><div class="el-p"><p dir="auto">multi head self attention<br>
self attention을 여러번 나눠서 계산하는 것임</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">다양한 관점에서의 weight를 계산하여 그 결과를 합쳐나간다고 이해하면 됨 마지막에 concat해서 합침</li>
<li data-line="1" dir="auto">실제 실험에서는 8개의 multi head를 사용함</li>
<li data-line="2" dir="auto">이것 또한 동일하게 병렬 처리가 가능</li>
<li data-line="3" dir="auto">각 head 별로 단어별 중요도가 다르게 나옴.</li>
<li data-line="4" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>그 "다양한" 관점의 기준은 누가 정하는가? : 누가 정하는 것이 아님. 학습 과정에서 자동으로 정해지는 것. 
<ul>
<li data-line="5" dir="auto">각 헤드가 독립적인 가중치 행렬을 가지는데, 각 해드가 다른 패턴을 포착하도록 자동ㅡ로 학습됨. 우리는 이해하지 못하겠지만 attention layer의 신경망이 어떠한 "패턴"을 찾을것임.</li>
<li data-line="6" dir="auto">근데 8개의 헤드가 각각 다른 패턴을 찾도록 하는것</li>
</ul>
</li>
</ul></div><div class="el-p"><p dir="auto">encoder<br>
multi head self attention + feed forward neural network의 반복 : input문장에 대한 representation 업데이트<br>
decoder<br>
encoder에서 생성된 representation -&gt; conditional 하게 문장 생성<br>
encoder에서는 key와 value만 넘어오며,  query는 decoder에서 계속 업데이트해나가는 방식임.</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>inference : 순차적으로 다음 단어 하나씩 예측하며 처리
<ol>
<li data-line="1" dir="auto">지금까지 생성한 단어들"까지"만 보고 (masked self-attention)</li>
<li data-line="2" dir="auto">다음 단어로 뭘 만들지를(query) 원문(encoder에서 생성된 representation) 참고하여</li>
<li data-line="3" dir="auto">새 단어를 생성함(feed forward)</li>
</ol>
<ul>
<li data-line="4" dir="auto">greedy search : 매번 가장 높은 확률의 다음 단어를 선택하지만, 이는 최적의 선택이 아닐 수 있음. </li>
<li data-line="5" dir="auto">beam search : 매번 가장 높은 확률의 다음 단어를 선택하는 것이 아님. 여러 후보를 유함</li>
</ul>
</li>
</ul></div></div></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="04" dir="auto" class="heading" id="04">04</h1><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="사전학습" dir="auto" class="heading" id="사전학습"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>사전학습</h3><div class="heading-children"><div class="el-p"><p dir="auto">word embedding의 pretraining</p></div></div></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="05" dir="auto" class="heading" id="05">05</h1><div class="heading-children"><div class="el-p"><p dir="auto">llm agent : 어떠한 특정환경과 상호작용할 수 있는 llm. 스스로 다음 절차를 생각해낼 수 있는 자율성과 반응성이라는 핵심 특징 존재.<br>
short-term memory : 현재 대화 세션 내에서만 유지되는 즉각적인 문맥 정보로 대화의 최근 몇 턴을 기억하며 주로 컨텍스트 윈도우에 저장<br>
long-term memory : 긴 대화 내용들을 저장해두고<br>
toolformer :<br>
MCP :<br>
Reasoning :<br>
planning :<br>
ReAct : reason and act planning을 하면서 계속 답을 내는 형태<br>
multi agent collaboration : supervised agent의 역할을 중심으로 ... </p></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="06" dir="auto" class="heading" id="06">06</h1><div class="heading-children"><div class="el-p"><p dir="auto">AI 하드웨어와 GPU</p></div><div class="mod-footer mod-ui"></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#01"><div class="tree-item-contents heading-link" heading-name="01"><span class="tree-item-title">01</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#머신러닝과_딥러닝"><div class="tree-item-contents heading-link" heading-name="머신러닝과 딥러닝"><span class="tree-item-title">머신러닝과 딥러닝</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#02"><div class="tree-item-contents heading-link" heading-name="02"><span class="tree-item-title">02</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#자연어_처리_모델"><div class="tree-item-contents heading-link" heading-name="자연어 처리 모델"><span class="tree-item-title">자연어 처리 모델</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#03"><div class="tree-item-contents heading-link" heading-name="03"><span class="tree-item-title">03</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#transformer와_attention"><div class="tree-item-contents heading-link" heading-name="transformer와 attention"><span class="tree-item-title">transformer와 attention</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#04"><div class="tree-item-contents heading-link" heading-name="04"><span class="tree-item-title">04</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#사전학습"><div class="tree-item-contents heading-link" heading-name="사전학습"><span class="tree-item-title">사전학습</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#05"><div class="tree-item-contents heading-link" heading-name="05"><span class="tree-item-title">05</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="lgaimers\강의수강_chapter02.html#06"><div class="tree-item-contents heading-link" heading-name="06"><span class="tree-item-title">06</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>