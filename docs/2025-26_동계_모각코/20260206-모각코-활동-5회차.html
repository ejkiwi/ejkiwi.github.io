<!DOCTYPE html> <html><head>
		<title>20260206 모각코 활동 5회차</title>
		<base href="../">
		<meta id="root-path" root-path="../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="ejkiwi.github.io - 20260206 모각코 활동 5회차">
		<meta property="og:title" content="20260206 모각코 활동 5회차">
		<meta property="og:description" content="ejkiwi.github.io - 20260206 모각코 활동 5회차">
		<meta property="og:type" content="website">
		<meta property="og:url" content="https://ejkiwi.github.io/2025-26_동계_모각코/20260206-모각코-활동-5회차.html">
		<meta property="og:image" content="undefined">
		<meta property="og:site_name" content="ejkiwi.github.io">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://ejkiwi.github.io/lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-light show-inline-title show-ribbon mk-readable-line mk-folder-lines mk-spaces-enabled mk-inline-context-enabled mk-flow-seamless"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..." style="border-radius:10px; border-width: 0px;"><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles"></style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="MAE (Masked Autoencoders Are Scalable Vision Learners)"><p dir="auto">MAE (Masked Autoencoders Are Scalable Vision Learners)</p></h1><div class="el-h1 heading-wrapper"><div class="heading-children"><div class="el-p"><p dir="auto"><a rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2111.06377" target="_blank">https://arxiv.org/abs/2111.06377</a></p></div><div class="el-p"><p dir="auto">자기지도학습 - 이미지의 일부를 가리고 복원하는 방식으로 표현을 학습하는 방법</p></div><div class="el-hr"><hr></div><div class="el-h2 heading-wrapper"><h2 data-heading="초록 분석" dir="auto" class="heading" id="초록_분석"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>초록 분석</h2><div class="heading-children"><div class="el-p"><p dir="auto"><em>"This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision."</em> <em>이 논문은 마스크 오토인코더(MAE)가 컴퓨터 비전에서 확장 가능한 자기지도학습 모델임을 보입니다.</em> <code>#MAE #maskedautoencoder #scalable</code> 핵심 키워드는 <strong>"scalable"</strong> — SimCLR이 "simple"을 강조했다면, MAE는 "크게 키워도 잘 된다"는 확장성을 강조함</p></div><div class="el-p"><p dir="auto"><em>"Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels."</em> <em>우리의 접근법은 단순합니다: 입력 이미지의 랜덤 패치를 마스킹하고 빠진 픽셀을 복원합니다.</em> NLP의 BERT와 유사한 발상 — BERT는 단어를 마스킹하고 예측, MAE는 이미지 패치를 마스킹하고 복원. 개념적으로는 단순하지만 구현에서 핵심적인 설계 선택들이 있음</p></div><div class="el-p"><p dir="auto"><em>"First, we develop an asymmetric encoder-decoder architecture... Second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task."</em> 두 가지 핵심 설계:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto"><strong>비대칭 인코더-디코더</strong>: 인코더는 보이는 패치만 처리 (마스크 토큰 없음), 디코더는 가볍게</li>
<li data-line="1" dir="auto"><strong>높은 마스킹 비율(75%)</strong>: 이미지 중복성이 높기 때문에, 쉬운 task가 되지 않으려면 많이 가려야 함</li>
</ul></div><div class="el-hr"><hr></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="핵심 개념 분석" dir="auto" class="heading" id="핵심_개념_분석"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>핵심 개념 분석</h2><div class="heading-children"><div class="el-h3 heading-wrapper"><h3 data-heading="왜 단순히 BERT를 이미지에 적용하면 안 될까?" dir="auto" class="heading" id="왜_단순히_BERT를_이미지에_적용하면_안_될까?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>왜 단순히 BERT를 이미지에 적용하면 안 될까?</h3><div class="heading-children"><div class="el-p"><p dir="auto">논문이 이 질문에 직접 답하는 게 인상적임. 세 가지 이유를 제시:</p></div><div class="el-p"><p dir="auto"><strong>아키텍처 차이</strong> — 기존엔 CNN이 주류라 마스크 토큰 같은 개념을 삽입하기 어려웠음. ViT 등장으로 해결됨</p></div><div class="el-p"><p dir="auto"><strong>정보 밀도 차이</strong> ← 이게 핵심!</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">언어: 단어 하나하나가 semantic하게 밀도 높음. 몇 개만 가려도 어려운 task</li>
<li data-line="1" dir="auto">이미지: 공간적 중복성이 매우 높음. 옆 픽셀에서 쉽게 추측 가능</li>
<li data-line="2" dir="auto">→ 해결책: <strong>아주 많이 가리기 (75%)</strong></li>
</ul></div><div class="el-p"><p dir="auto"><strong>디코더의 역할 차이</strong></p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">BERT 디코더: 의미 있는 단어를 예측 → 간단한 MLP로도 충분</li>
<li data-line="1" dir="auto">MAE 디코더: 픽셀값을 복원 → 낮은 semantic 수준, 디코더 설계가 중요해짐</li>
</ul></div><div class="el-hr"><hr></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="아키텍처: 비대칭 인코더-디코더" dir="auto" class="heading" id="아키텍처:_비대칭_인코더-디코더"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>아키텍처: 비대칭 인코더-디코더</h3><div class="heading-children"><div class="el-p"><p dir="auto"><strong>인코더 (무거움)</strong></p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">보이는 패치(25%)만 처리 → 마스크 토큰 없음</li>
<li data-line="1" dir="auto">표준 ViT 구조 사용</li>
<li data-line="2" dir="auto">포지셔널 임베딩 추가</li>
</ul></div><div class="el-p"><p dir="auto"><strong>디코더 (가벼움)</strong></p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">인코더 출력 + 마스크 토큰을 모두 받아서 처리</li>
<li data-line="1" dir="auto">인코더보다 훨씬 작음 (FLOPs 기준 ~9% 수준)</li>
<li data-line="2" dir="auto"><strong>Pre-training 때만 사용</strong> → fine-tuning 시엔 버림</li>
</ul></div><div class="el-p"><p dir="auto">왜 이 설계가 효율적인가? 인코더가 전체 패치의 25%만 처리하니 연산량이 대폭 줄어듦. 논문 실험 기준 <strong>3× 이상 학습 속도 향상</strong></p></div><div class="el-hr"><hr></div></div></div><div class="el-h3 heading-wrapper"><h3 data-heading="Reconstruction Target: 픽셀을 예측한다" dir="auto" class="heading" id="Reconstruction_Target:_픽셀을_예측한다"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Reconstruction Target: 픽셀을 예측한다</h3><div class="heading-children"><div class="el-p"><p dir="auto">손실 함수는 <strong>MSE (Mean Squared Error)</strong> — 마스킹된 패치에 대해서만 계산 (BERT와 동일한 방식)</p></div><div class="el-p"><p dir="auto">흥미로운 변형: <strong>패치별 정규화(normalized pixels)</strong></p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">각 패치의 픽셀값을 해당 패치의 평균/표준편차로 정규화해서 예측 target으로 사용</li>
<li data-line="1" dir="auto">로컬 대비(local contrast)를 강화 → 실험 결과 성능 향상</li>
</ul></div><div class="el-p"><p dir="auto">토큰 기반 방법(BEiT 등)과 비교했을 때 픽셀 기반도 충분히 좋거나 더 나음 → 복잡한 tokenizer 없이도 잘 된다는 게 MAE의 강점</p></div><div class="el-hr"><hr></div></div></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="주요 실험 결과" dir="auto" class="heading" id="주요_실험_결과"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>주요 실험 결과</h2><div class="heading-children"><div class="el-p"><p dir="auto"><strong>마스킹 비율의 영향</strong> (Figure 5)</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">fine-tuning: 40~80% 범위에서 전반적으로 잘 됨, 75%가 sweet spot</li>
<li data-line="1" dir="auto">linear probing: 비율이 높을수록 꾸준히 향상. 75%가 최적</li>
<li data-line="2" dir="auto">BERT의 15%와 대조적으로 <strong>이미지에선 왜 75%가 필요한지</strong> 직접 실험으로 보여줌</li>
</ul></div><div class="el-p"><p dir="auto"><strong>주요 성능</strong> (Table 3)</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">ViT-H로 ImageNet-1K에서 <strong>87.8% top-1</strong> 달성 — IN1K 데이터만 사용한 방법 중 최고</li>
<li data-line="1" dir="auto">supervised pre-training보다 transfer learning 성능도 좋음</li>
</ul></div><div class="el-p"><p dir="auto"><strong>학습 효율</strong></p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">BEiT보다 <strong>3.5× 빠름</strong> (인코더에서 마스크 토큰 제거 덕분)</li>
<li data-line="1" dir="auto">MoCo v3보다 적은 epoch에서 더 높은 성능</li>
</ul></div><div class="el-hr"><hr></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="SimCLR과 비교해서 흥미로운 점" dir="auto" class="heading" id="SimCLR과_비교해서_흥미로운_점"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>SimCLR과 비교해서 흥미로운 점</h2><div class="heading-children"><div class="el-p"><p dir="auto">data augmentation 의존도 차이가 흥미로움. SimCLR은 crop+color distortion 조합이 없으면 성능이 크게 떨어지는데, MAE는 random masking 자체가 augmentation 역할을 하기 때문에 크게 의존하지 않음.</p></div><div class="el-hr"><hr></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="한 줄 요약" dir="auto" class="heading" id="한_줄_요약"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>한 줄 요약</h2><div class="heading-children"><div class="el-p"><p dir="auto">MAE = "이미지의 75%를 가리고 복원하는 task를 통해, 라벨 없이도 지도학습을 능가하는 표현을 학습한다. 핵심은 비대칭 구조로 빠르게, 높은 마스킹 비율로 어렵게."<br>
코드 구현 시 rotation 기반과의 가장 큰 차이는 <strong>task의 성격</strong> — rotation은 분류(4-class), MAE는 픽셀 복원(regression+MSE)이라는 점, 그리고 <strong>아키텍처도 ViT 기반</strong>이어야 패치 단위 마스킹이 자연스럽다는 점이 구현에서 핵심 고려사항이 될 것 같음!</p></div><div class="mod-footer mod-ui"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#MAE (Masked Autoencoders Are Scalable Vision Learners)"><div class="tree-item-contents heading-link" heading-name="MAE (Masked Autoencoders Are Scalable Vision Learners)"><span class="tree-item-title">MAE (Masked Autoencoders Are Scalable Vision Learners)</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#초록_분석"><div class="tree-item-contents heading-link" heading-name="초록 분석"><span class="tree-item-title">초록 분석</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#핵심_개념_분석"><div class="tree-item-contents heading-link" heading-name="핵심 개념 분석"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">핵심 개념 분석</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="3"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#왜_단순히_BERT를_이미지에_적용하면_안_될까?"><div class="tree-item-contents heading-link" heading-name="왜 단순히 BERT를 이미지에 적용하면 안 될까?"><span class="tree-item-title">왜 단순히 BERT를 이미지에 적용하면 안 될까?</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#아키텍처:_비대칭_인코더-디코더"><div class="tree-item-contents heading-link" heading-name="아키텍처: 비대칭 인코더-디코더"><span class="tree-item-title">아키텍처: 비대칭 인코더-디코더</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#Reconstruction_Target:_픽셀을_예측한다"><div class="tree-item-contents heading-link" heading-name="Reconstruction Target: 픽셀을 예측한다"><span class="tree-item-title">Reconstruction Target: 픽셀을 예측한다</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#주요_실험_결과"><div class="tree-item-contents heading-link" heading-name="주요 실험 결과"><span class="tree-item-title">주요 실험 결과</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#SimCLR과_비교해서_흥미로운_점"><div class="tree-item-contents heading-link" heading-name="SimCLR과 비교해서 흥미로운 점"><span class="tree-item-title">SimCLR과 비교해서 흥미로운 점</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="2025-26_동계_모각코\20260206-모각코-활동-5회차.html#한_줄_요약"><div class="tree-item-contents heading-link" heading-name="한 줄 요약"><span class="tree-item-title">한 줄 요약</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>