<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[ejkiwi.github.io]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://ejkiwi.github.io/</link><image><url>https://ejkiwi.github.io/lib/media/favicon.png</url><title>ejkiwi.github.io</title><link>https://ejkiwi.github.io/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sun, 01 Dec 2024 07:59:19 GMT</lastBuildDate><atom:link href="https://ejkiwi.github.io/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 01 Dec 2024 07:59:19 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[ë°±ì¤€í’€ì´]]></title><description><![CDATA[ 
 <br>ğŸ¥ <a data-href="20240813 ëª¨ê°ì½” í™œë™ 7íšŒì°¨" href="https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240813-ëª¨ê°ì½”-í™œë™-7íšŒì°¨.html" class="internal-link" target="_self" rel="noopener nofollow">20240813 ëª¨ê°ì½” í™œë™ 7íšŒì°¨</a>]]></description><link>https://ejkiwi.github.io/ë°±ì¤€í’€ì´/ë°±ì¤€í’€ì´.html</link><guid isPermaLink="false">ë°±ì¤€í’€ì´/ë°±ì¤€í’€ì´.md</guid><pubDate>Sun, 01 Dec 2024 07:58:34 GMT</pubDate></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br><br>
<br><a data-href="2024_ì—¬ë¦„_ëª¨ê°ì½”" href="https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/2024_ì—¬ë¦„_ëª¨ê°ì½”.html" class="internal-link" target="_self" rel="noopener nofollow">2024_ì—¬ë¦„_ëª¨ê°ì½”</a>
<br><a data-href="ë°±ì¤€í’€ì´" href="https://ejkiwi.github.io/ë°±ì¤€í’€ì´/ë°±ì¤€í’€ì´.html" class="internal-link" target="_self" rel="noopener nofollow">ë°±ì¤€í’€ì´</a>
<br><br>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@eonjikiwi/posts" rel="noopener nofollow" class="external-link" href="https://velog.io/@eonjikiwi/posts" target="_blank">ejkiwi_velog</a>
]]></description><link>https://ejkiwi.github.io/index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Tue, 26 Nov 2024 18:51:57 GMT</pubDate></item><item><title><![CDATA[2024_ì—¬ë¦„_ëª¨ê°ì½”]]></title><description><![CDATA[ 
 ]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/2024_ì—¬ë¦„_ëª¨ê°ì½”.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/2024_ì—¬ë¦„_ëª¨ê°ì½”.md</guid><pubDate>Tue, 26 Nov 2024 18:04:57 GMT</pubDate></item><item><title><![CDATA[ëª¨.êµ¬.ëª¨.êµ¬ ëª¨ê°ì½” í™œë™]]></title><description><![CDATA[ 
 <br>íŒ€ ëª¨ê°ì½” ëª©í‘œ : 1. ì ˆëŒ€ í¬ê¸°í•˜ì§€ ì•Šê¸°, 2. ëª¨ë¥´ëŠ” ê±° ê·¸ëƒ¥ ë„˜ì–´ê°€ì§€ ì•Šê¸°<br>ë‚˜ì˜ ëª¨ê°ì½” í™œë™ ë‹¤ì§ : í™œë™ ê³„íšì„ ì™„ë²½íˆ ë§ˆë¬´ë¦¬ í•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤!<br>ë‚˜ì˜ ëª¨ê°ì½” í™œë™ ê³„íš<br>
<br>7ì›” 7ì¼

<br>ëª¨ê°ì½” í™œë™ ë™ì•ˆ ê³µë¶€í•  ì£¼ì œ ì „ì²´ì ìœ¼ë¡œ í†ºì•„ë³´ê¸°, íŒ€ì›ë“¤ê³¼ ì¹œí•´ì§€ê¸°


<br>7ì›” 9ì¼, 7ì›” 16ì¼

<br>íŒŒì´í† ì¹˜ ì‚¬ìš© ìµíˆê¸°
<br>ì„ ë°°ë‹˜ í”„ë¡œì íŠ¸ì˜ ë ˆí¬ì§€í† ë¦¬ì— ìˆëŠ” ì½”ë“œ ë¶„ì„í•´ë³´ë©° ê³µë¶€í•˜ê¸°


<br>7ì›” 23ì¼, 7ì›” 30ì¼, 8ì›” 6ì¼, 8ì›” 13ì¼

<br>CNN êµ¬ì¡° ê³µë¶€í•˜ê¸°
<br>RESNET êµ¬ì¡° ê³µë¶€í•˜ê¸°


<br>ëª¨ê°ì½” íŒ€ë¸”ë¡œê·¸<br>
<a data-tooltip-position="top" aria-label="https://jolly-exoplanet-ef1.notion.site/1868305015324f9f84670142f4029fb7" rel="noopener nofollow" class="external-link" href="https://jolly-exoplanet-ef1.notion.site/1868305015324f9f84670142f4029fb7" target="_blank">ëª¨.êµ¬.ëª¨.êµ¬_íŒ€ë¸”ë¡œê·¸</a>]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/ëª¨.êµ¬.ëª¨.êµ¬-ëª¨ê°ì½”-í™œë™.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/ëª¨.êµ¬.ëª¨.êµ¬ ëª¨ê°ì½” í™œë™.md</guid><pubDate>Tue, 26 Nov 2024 17:34:04 GMT</pubDate></item><item><title><![CDATA[20240707 ëª¨ê°ì½” í™œë™ 1íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ ëª©í‘œ<br>
1.ëª¨ê°ì½” í™œë™ ë™ì•ˆ ê³µë¶€í•  ì£¼ì œ ì „ì²´ì ìœ¼ë¡œ í†ºì•„ë³´ê¸°<br>
2.íŒ€ì›ë“¤ê³¼ ì¹œí•´ì§€ê¸°<br>íŒŒì´í† ì¹˜<br>
<br>pythonì„ ë°”íƒ•ìœ¼ë¡œ ì œì‘ëœ, ë”¥ëŸ¬ë‹ê³¼  ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì—ì„œ ì£¼ë¡œ í™œìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
<br>pytorchì˜ ì—°ì‚°ì€ tensorë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ì—¬ ì‘ë™
<br>tensor : íŒŒì´í† ì¹˜ì˜ ê¸°ë³¸ ë°ì´í„° íƒ€ì…. ë°°ì—´ì´ë‚˜ í–‰ë ¬ê³¼ ìœ ì‚¬í•œ êµ¬ì¡°(ë‹¤ì°¨ì› ë°°ì—´)ì´ë‹¤.
<br>íŒŒì´í† ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ëœ ëª¨ë¸ì€ í•™ìŠµì„ ìœ„í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•œë‹¤. -&gt; ìë™ ë¯¸ë¶„
<br>ê·¸ë˜ë””ì–¸íŠ¸ : ë²¡í„° ë¯¸ë¶„ì˜ ê²°ê³¼ (=í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°, ê° ë³€ìˆ˜ì— ëŒ€í•œ ë³€í™”ìœ¨)
<br>ì„ ë°°ë‹˜ì˜ í”„ë¡œì íŠ¸<br>
<br><a data-tooltip-position="top" aria-label="https://github.com/b-re-w/2024-1_BPL_STalk_Model_Research" rel="noopener nofollow" class="external-link" href="https://github.com/b-re-w/2024-1_BPL_STalk_Model_Research" target="_blank">2024-1_BPL_STalk_Model_Research</a>
<br>CNN ëª¨ë¸<br>
<br>2ì°¨ì› ë°ì´í„° (ì´ë¯¸ì§€ ë“±)ì˜ íŒ¨í„´ì„ ì¸ì‹í•˜ê³  ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸.
<br>ì—¬ëŸ¬ê°œì˜ ì¸µìœ¼ë¡œ êµ¬ì„±ë¨.
<br>ì¸ê°„ì˜ ì‹œì‹ ê²½ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ êµ¬ì¡°ì„
<br>ì´ë¯¸ì§€ì˜ 
<br>RESNET ëª¨ë¸<br>
<br>CNN ëª¨ë¸ì— ì”ì°¨ ì—°ê²° ê°œë…ì„ ë„ì…í•œ ê²ƒ.
<br>ì”ì°¨ ì—°ê²° : ê° ì¸µì˜ ì¶œë ¥ì„ ë‹¤ìŒ ì¸µìœ¼ë¡œ ì§ì ‘ ë³´ë‚´ëŠ” ëŒ€ì‹ ì—, ì…ë ¥ì„ ë”í•œ ë’¤ ë‹¤ìŒ ì¸µìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ì—°ê²°.
]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240707-ëª¨ê°ì½”-í™œë™-1íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240707 ëª¨ê°ì½” í™œë™ 1íšŒì°¨.md</guid><pubDate>Mon, 15 Jul 2024 07:48:10 GMT</pubDate></item><item><title><![CDATA[20240709 ëª¨ê°ì½” í™œë™ 2íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ ëª©í‘œ<br>
1.íŒŒì´í† ì¹˜ ê³µë¶€í•˜ê¸° - youtubeì— ìˆëŠ” íŒŒì´í† ì¹˜ ì„¤ëª… ê°•ì¢Œ(<a rel="noopener nofollow" class="external-link" href="https://youtube.com/playlist?list=PLS8gIc2q83Oit-utRso2iblvt00fZOw85&amp;si=i0CZi4e5g_dVJ3dx" target="_blank">https://youtube.com/playlist?list=PLS8gIc2q83Oit-utRso2iblvt00fZOw85&amp;si=i0CZi4e5g_dVJ3dx</a>) 1,2,3ê°• ë“¤ìœ¼ë©° ê³µë¶€<br>
2.ì„ ë°°ë‹˜ì˜ í”„ë¡œì íŠ¸ ì½”ë“œ ì ˆë°˜ ë¶„ì„í•˜ê¸° - whisper ë¶€ë¶„<br>íŒŒì´í† ì¹˜<br>
alë¶„ì•¼ì—ì„œ google tensorflowì™€ í•¨ê»˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  í•™ìŠµí•˜ëŠ” ë° ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì„.<br>
<br>ì˜¤í”ˆì†ŒìŠ¤ : ê°œë°©í˜• í˜‘ì—…ì„ ì¥ë ¤í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ëª¨ë¸
<br>í”„ë ˆì„ì›Œí¬ : ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì— ìˆì–´ í•˜ë‚˜ì˜ ë¼ˆëŒ€ì™€ ê°™ì€ ì—­í• ì„ í•˜ëŠ” ê²ƒìœ¼ë¡œ, ëª©ì ì— í•„ìš”í•œ ê²ƒì„ ê³ ë¯¼í•  í•„ìš” ì—†ì´ ì´ìš©í•  ìˆ˜ ìˆë„ë¡ ì¼ê´„ë¡œ ê°€ì ¸ë‹¤ ì“°ë„ë¡ ë§Œë“¤ì–´ ë†“ì€ êµ¬ì¡°í™”ëœ í‹€ì„.<br>
í…ì„œ : íŒŒì´í† ì¹˜ì˜ ê¸°ë³¸ ë°ì´í„° íƒ€ì…
<br>ë°°ì—´ì´ë‚˜ í–‰ë ¬ê³¼ ìœ ì‚¬í•œ ìë£Œ êµ¬ì¡°ì´ë‹¤
<br>ì¼ë°˜ì ìœ¼ë¡œëŠ” 1ì°¨ì› - ë²¡í„° , 2ì°¨ì› - í–‰ë ¬, 3ì°¨ì› ì´ìƒ - ë²¡í„° ì´ì§€ë§Œ, íŒŒì´í† ì¹˜ì—ì„œëŠ” ì…ë ¥ê³¼ ì¶œë ¥ ê·¸ë¦¬ê³  í•™ìŠµì— í•„ìš”í•œëª¨ë“  ë°ì´í„°ë“¤ì„ ëª¨ë‘ í…ì„œ ë°ì´í„°íƒ€ì…ìœ¼ë¡œ ì •ì˜í•˜ê³  ìˆë‹¤.
<br>í…ì„œì˜ ì†ì„±ìœ¼ë¡œëŠ” ëª¨ì–‘,ìë£Œí˜•,ì €ì¥ë˜ëŠ” ìœ„ì¹˜ê°€ ìˆë‹¤
<br>ë³´í†µ ì €ì¥ë˜ëŠ” ìœ„ì¹˜ëŠ” cpuì¸ë°, gpuë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ë©´, .to("cuda")ë¥¼ ì‚¬ìš©í•´ì„œ í…ì„œë¥¼ gpuë¡œ ì´ë™ì‹œí‚¬ ìˆ˜ ìˆë‹¤.

<br>gpu : ì»´í“¨í„° ê·¸ë˜í”½ì„ ì²˜ë¦¬í•˜ëŠ” ì¥ì¹˜ë¡œ ê·¸ë˜í”½ ì¹´ë“œë¥¼ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ìš”ì†Œ.


<br>1.íŒŒì´ì¬ì˜ ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë¡œë¶€í„° ì§ì ‘ í…ì„œë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.<br>
- listdata = [[10,20],[30,40]] 	tensor1 = torch.Tensor(listdata)`
<br>2.íŒŒì´ì¬ì˜ ë„˜íŒŒì´ ë°ì´í„°ë¡œë¶€í„° ì§ì ‘ í…ì„œë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆë‹¤.(ë„˜íŒŒì´ë¡œë§Œë“¤ì–´ì§„ê±´ ë³´í†µ intë¡œ ìƒì„±ë˜ê¸°ë•Œë¬¸ì— ì›ë˜ ë°ì´í„°ê°€ floatì˜ í˜•íƒœì¸ ê²½ìš°, ìºìŠ¤íŒ…í•´ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ê¸°ë„ í•˜ë‹¤.)
<br>3.íŒŒì´ì¬ì˜ ëœë¤ ë°ì´í„°ë¡œë¶€í„° ì§ì ‘ í…ì„œë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆë‹¤.<br>
- tensor3 = torch.rand(2,2) -&gt; rand()ë©”ì„œë“œëŠ” 0~1ì‚¬ì´ì˜ ê· ì¼ ë¶„í¬ ëœë¤ê°’ì„ ìƒì„±í•¨ ( randn()ë©”ì„œë“œëŠ” ì •ê·œë¶„í¬ë¥¼ ê°€ì§€ëŠ” ëœë¤ê°’ì„ ìƒì„± )
<br>í…ì„œë¥¼ ë„˜íŒŒì´ë¡œ ë°”ê¿€ ìˆ˜ë„ ìˆë‹¤.<br>
- tensor.numpy()
<br>ì¸ë±ì‹±ê³¼ ìŠ¬ë¼ì´ì‹±ì´ ê°€ëŠ¥í•˜ë‹¤
<br>elment-wise product ì—°ì‚° 
<br>matrix multiplication ì—°ì‚° (í–‰ë ¬ê³±)
<br>í…ì„œë¥¼ í•©ì¹  ìˆ˜ ìˆë‹¤. Tensor Concatenate (dim=0 ì„¸ë¡œ, dim=1 ê°€ë¡œ)<br>
íŒŒì´í† ì¹˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¡° :<br>
1.ë°ì´í„°ì •ì˜<br>
- ê¸°ë³¸ ë°ì´í„°íƒ€ì…ì¸ TENSORë¡œ ìƒì„±í•´ì•¼í•¨.<br>
- TensorDataset(x_train,y_train) : í…ì„œ ë°ì´í„°ì…‹ ìƒì„±<br>
- DataLoader(dataset, batch_size, shuffle) : ë¯¸ë‹ˆ ë°°ì¹˜ í•™ìŠµê³¼ ë°ì´í„° ì…”í”Œ, ë©€í‹° í”„ë¡œì„¸ì‹± ë“±ì„ ê°„ë‹¨í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ.<br>
- ë¯¸ë‹ˆ ë°°ì¹˜ í•™ìŠµ : ì „ì²´ ë°ì´í„°ë¥¼ në“±ë¶„ í•˜ì—¬ ê°ê°ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒ.<br>
- ë°ì´í„° ì…”í”Œ : trainë°ì´í„°ì™€testë°ì´í„° ê°„ì˜ ë™ì¼í•œ ë¶„í¬ë¥¼ ê°€ì§€ë„ë¡ ì„ì–´ëŠ” ê²ƒ.<br>
- ë©€í‹° í”„ë¡œì„¸ì‹± : ì—¬ëŸ¬ ì‘ì—…ì„ ë³„ë„ì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒì„± í›„ ë³‘ë ¬ì²˜ë¦¬ë¥¼ í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê¸° ë•Œë¬¸ì— ë” ë¹ ë¥´ê²Œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.<br>
2.ëª¨ë¸êµ¬ì¶•<br>
- nn.Moduleì„ ìƒì†ë°›ëŠ” classë¥¼ ìƒì„±í•˜ì—¬ ì •ì˜í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤.<br>
- í´ë˜ìŠ¤ ì† __init__í•¨ìˆ˜ì—ì„œ ê³„ì¸µ(ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ”)ì„ ì •ì˜.<br>
- í´ë˜ìŠ¤ ì† forward í•¨ìˆ˜ì—ì„œ ì‹ ê²½ë§ì— ë°ì´í„° ì „ë‹¬í•˜ê¸°ë¥¼ ìˆ˜í•˜ê³ , ê²°ê³¼ê°’ì„ ë¦¬í„´í•¨<br>
3.í”¼ë“œí¬ì›Œë“œ<br>
- ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” í”¼ë“œ í¬ì›Œë“œ ê³„ì‚°ê°’ê³¼ ì •ë‹µì˜ ì°¨ì´ ê³„ì‚°ì´ í•„ìš”  -&gt; ì´ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” ì†ì‹¤í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €ê°€ í•„ìš”í•¨.<br>
- ì†ì‹¤í•¨ìˆ˜ : MSE ë“±<br>
- ì˜µí‹°ë§ˆì´ì € : SDG, ADAM<br>
4.ì†ì‹¤í•¨ìˆ˜ê³„ì‚°<br>
- nn.MSELoss(model(x_train),y_train) : í”¼ë“œí¬ì›Œë“œ ê³„ì‚° ê°’ê³¼ ì •ë‹µê³¼ì˜ ì˜¤ì°¨ ê³„ì‚°.<br>
- ì´ ë•Œ, modelì— ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ë©´ model í´ë˜ìŠ¤ ì•ˆì— ìˆëŠ” forward()í•¨ìˆ˜ìë™ìœ¼ë¡œ forward()í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸ì— ìš°ë¦¬ê°€ ë”°ë¡œ í˜¸ì¶œí•´ì¤„ í•„ìš”ê°€ ì—†ë‹¤.<br>
5.ëª¨ë¸í•™ìŠµ<br>
-ì—­ì „íŒŒ ì½”ë“œ : í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ì„œ ëª¨ë¸ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤)ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ ìµœì í™” ì‹œí‚¨ë‹¤<br>
- optimizer.zero.grad()<br>
- loss.backward()<br>
- optimizer.step()<br>
- ëª¨ë¸(model) : ê° ì¸µì„ í¬í•¨í•˜ê³  ìˆëŠ” ì¸ê³µì‹ ê²½ë§ ê·¸ ìì²´ (ì´ë¥¼ ë ˆê³ ì²˜ëŸ¼ ìˆœì°¨ì ìœ¼ë¡œ ìŒ“ê¸° -&gt; CNN, RNN ë“± ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥)<br>
- 3&gt;4&gt;5ì˜ ë°˜ë³µ -&gt; ë”¥ëŸ¬ë‹ í•™ìŠµ<br>
- ì†ì‹¤í•¨ìˆ˜ê°€ ìµœì†Œê°€ ë  ë•Œê¹Œì§€ ëª¨ë¸ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜, ë°”ì´ì–´ìŠ¤) ê°’ì„ ì°¾ì•„ê°.
<br>ì„ ë°°ë‹˜ í”„ë¡œì íŠ¸ ë¶„ì„ - whisper<br>
1.from faster_whisper import WhisperModel<br>
2.def get_whisper() :  	 3.   model_size = "medium"  #@param ['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3'] 	 4.   compute_type = "int8"  #@param ['float16', 'int8']<br>
5.   return WhisperModel(model_size, device=DEVICE, cpu_threads=12, compute_type=compute_type).transcribe<br>1: faster_whisper ì—ì„œ WhisperModel ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°<br>
2: get_whisper ë¼ëŠ” ì´ë¦„ì˜ í•¨ìˆ˜ ì„¤ì •í•˜ê¸°<br>
3: model_sizeëŠ” "medium"ì´ë‹¤. model_sizeê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì˜µì…˜ìœ¼ë¡œëŠ” "tiny","base","small","medium","large","large-v3" ì´ ìˆë‹¤. -&gt; model_sizeëŠ” ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ëœ»í•œë‹¤.<br>
4: compute_typeì€ "int8"ì´ë‹¤. compute_typeì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì˜µì…˜ìœ¼ë¡œëŠ” "float16","int8"ì´ ìˆë‹¤. -&gt; compute_typeì€ ê³„ì‚° ìœ í˜•ì„ ëœ»í•œë‹¤.<br>
5: WhisperModelì€ 4ê°€ì§€ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ì—¬ê¸°ì—ì„œ model_sizeëŠ” ì•ì„œ ì •í•œ í¬ê¸°ì™€ ê°™ê³ , deviceëŠ” ëª¨ë¸ì´ ì‹¤í–‰ë  ì¥ì¹˜ë¥¼ ì§€ì •í•œë‹¤. cpu_threadsëŠ” CPUì˜ ìŠ¤ë ˆë“œ ìˆ˜ë¥¼ ëœ»í•œë‹¤. compute_typeë˜í•œ ì•ì„œ ì •í•œ ê³„ì‚° ìœ í˜•ê³¼ ê°™ë‹¤. ì´ ë•Œ .transcribeëŠ” ëª¨ë¸ì˜ ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì„ í˜¸ì¶œí•´ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì¤€ë‹¤.]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240709-ëª¨ê°ì½”-í™œë™-2íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240709 ëª¨ê°ì½” í™œë™ 2íšŒì°¨.md</guid><pubDate>Mon, 15 Jul 2024 06:27:57 GMT</pubDate></item><item><title><![CDATA[20240716 ëª¨ê°ì½” í™œë™ 3íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ ëª©í‘œ<br>
1.íŒŒì´í† ì¹˜ ê³µë¶€í•˜ê¸°  - ì‹¤ìŠµí•´ë³´ê¸°<br>
2.ì„ ë°°ë‹˜ì˜ í”„ë¡œì íŠ¸ ì½”ë“œ ì ˆë°˜ ë¶„ì„í•˜ê¸° - resnet ë¶€ë¶„<br>íŒŒì´í† ì¹˜ ì‹¤ìŠµ<br>import torch #íŒŒì´í† ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
from torch import nn #í† ì¹˜ì—ì„œ nn ë¶ˆëŸ¬ì˜¤ê¸°
  

#í…ì„œ í˜•íƒœë¡œ trainë°ì´í„° ê°€ì ¸ì˜¤ê¸°
x_train = torch.Tensor([1,2,3,4,5,6]).view(6,1)
y_train = torch.Tensor([3,6,9,12,15,18]).view(6,1)

  
#MyNeuralNetwork í´ë˜ìŠ¤ ë§Œë“¤ê¸°. nn.Moduleì´ ë¶€ëª¨í´ë˜ìŠ¤ê°€ ë¨.
class MyNeuralNetwork(nn.Module):
&nbsp; def __init__(self):
&nbsp; &nbsp; super().__init__()
&nbsp; &nbsp; self.linear_relu_stack = nn.Sequential(nn.Linear(1,1))

&nbsp; def forward(self, x):
&nbsp; &nbsp; logits = self.linear_relu_stack(x)
&nbsp; &nbsp; return logits


#ëª¨ë¸
model = MyNeuralNetwork()
#ì†ì‹¤í•¨ìˆ˜
loss_function = nn.MSELoss()
#ì˜µí‹°ë§ˆì´ì €
optimizer = torch.optim.SGD(model.parameters(),lr=1e-2)

nums_epoch = 2000


#í•™ìŠµì‹œí‚¤ê¸°
for epoch in range(nums_epoch + 1):
&nbsp; prediction = model(x_train)
&nbsp; loss = loss_function(prediction, y_train)

&nbsp; optimizer.zero_grad()
&nbsp; loss.backward()
&nbsp; optimizer.step()

&nbsp; if epoch % 100 == 0:
&nbsp; &nbsp; print('epoch = ', epoch, 'current loss = ', loss.item())
<br>#ì˜ˆì¸¡í•˜ê¸°
x_test = torch.Tensor([8,9,10,11]).view(4,1)
pred = model(x_test)
pred
<br>ì„ ë°°ë‹˜ì˜ í”„ë¡œì íŠ¸ ì½”ë“œ<br>from huggingface_hub import hf_hub_download
import wespeaker
<br>from huggingface_hub import hf_hub_download<br>
huggingface_hub ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ì„œ hf_hub_downloadí•¨ìˆ˜ë¥¼ ê°€ì ¸ì™€ì¤€ë‹¤.<br>
hf_hub_downloadí•¨ìˆ˜ë¥¼ í†µí•´ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆë‹¤.<br>
ê¸°ë³¸ì ìœ¼ë¡œ, í•¨ìˆ˜ì—ëŠ” repo_idì™€ repo_typeì„ ì¸ìë¡œ ë„˜ê²¨ì¤€ë‹¤. (revision - íŠ¹ì • ë²„ì „ì˜ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•˜ê³  ì‹¶ì„ ì‹œ. / local_dir íŠ¹ì • ìœ„ì¹˜ì— ì €ì¥í•˜ê³  ì‹¶ì„ ì‹œ.)<br>
import wespeaker<br>
wespeakerì„ ê°€ì ¸ì™€ì¤€ë‹¤.<br> def get_resnet152():
    model_id = "Wespeaker/wespeaker-voxceleb-resnet152-LM"
    model_name = model_id.replace("Wespeaker/wespeaker-", "").replace("-", "_")
 
    root_dir = hf_hub_download(model_id, filename=model_name+".onnx").replace(model_name+".onnx", "")

    import os
    if not os.path.isfile(root_dir+"avg_model.pt"):
        os.rename(hf_hub_download(model_id, filename=model_name+".pt"), root_dir+"avg_model.pt")
    if not os.path.isfile(root_dir+"config.yaml"):
        os.rename(hf_hub_download(model_id, filename=model_name+".yaml"), root_dir+"config.yaml")

    resnet = wespeaker.load_model_local(root_dir)

    #print("Compile model for the NPU")
    #resnet.model = intel_npu_acceleration_library.compile(resnet.model)

    def resnet152(ado, sample_rate=None):
        if isinstance(ado, str):
            return resnet.recognize(ado)
        else:
            return recognize(resnet, ado, sample_rate)

    resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)

    return resnet152
<br>ë¶„ì„<br>
def get_resnet152():<br>
get_resnet 152 ë¼ëŠ” ì´ë¦„ì˜ í•¨ìˆ˜ë¥¼ ì •ì˜<br>model_id = "Wespeaker/wespeaker-voxceleb-resnet152-LM"<br>
model_idë¼ëŠ” ë³€ìˆ˜ì— "Wespeaker/wespeaker-voxceleb-resnet152-LM"ë¥¼ ì§€ì •. ì•„ë§ˆ  ëª¨ë¸ ì•„ì´ë””ì— ëª¨ë¸ì˜ ì´ë¦„ì„ ì €ì¥í•œ ê²ƒì¼ ê²ƒ.<br>moldelname = model.id.replace("Wespeaker/wespeaker-",").replace("-", " ")<br>
model_nameì´ë¼ëŠ” ë³€ìˆ˜ë¥¼ ë§Œë“¤ì–´ì„œ, model_idë¥¼ ì•½ê°„ ë³€í˜•ì‹œí‚¨ ì´ë¦„ìœ¼ë¡œ ì§€ì •í•´ì¤Œ. "voxceleb_resnet152_LM"ì´ ë  ê²ƒ.<br>root_dir = hf_hub_download(model_id, filename = model_name+" .onnx").replace(model_name+" .onnx", "")<br>
hf_hub_download : huggingface_hub ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ì„œ ê°€ì ¸ì™”ë˜ í•¨ìˆ˜. í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì„ root_dirì— ì €ì¥í•¨.<br>import os<br>
os ëª¨ë“ˆì„ ê°€ì ¸ì˜´<br>
os ëª¨ë“ˆ : íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ì‘ì—…, í”„ë¡œì„¸ìŠ¤ ë° ìŠ¤ë ˆë“œ ê´€ë¦¬, ì‹œìŠ¤í…œ ì •ë³´ì™€ ê´€ë ¨í•œ ì‘ì—…ë“¤ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì´ë‹¤.<br>if not os.path.isfile(root_dir+"avg_model.pt"):<br>
os.rename(hf_hub_download(model_id, filename=model_name+".pt"), root_dir+"avg_model.pt")<br>
ë§Œì•½ avg_model.ptì´ë¦„ì„ ê°€ì§„ íŒŒì¼ì´ ì—†ë‹¤ë©´, ëª¨ë¸ì˜ ptíŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•œ ë’¤ ì´ë¦„ì„ avg_model.ptë¡œ ë°”ê¾¸ì–´ì„œ root_dir ë³€ìˆ˜ì— ì €ì¥í•¨.<br>
os.path.isfile(path) : pathê°€ íŒŒì¼ì¸ ê²½ìš° trueë¥¼ ë¦¬í„´, ì•„ë‹ˆë©´ falseë¥¼ ë¦¬í„´.<br>
os.rename : íŒŒì¼ ë˜ëŠ” í´ë”ì˜ ì´ë¦„ì„ ê°„ë‹¨íˆ ë³€ê²½í•  ìˆ˜ ìˆë‹¤.<br>if not os.path.isfile(root_dir+"config.yaml"):<br>
os.rename(hf_hub_download(model_id, filename=model_name+".yaml"), root_dir+"config.yaml")<br>
ì• ì½”ë“œì™€ ê°™ì€ ëŠë‚Œì¸ë°, ë§Œì•½ config.yamlíŒŒì¼ì´ ì—†ìœ¼ë©´ ëª¨ë¸ì˜ yamlíŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•œ ë’¤ ì´ë¦„ì„ ë°”ê¾¸ì–´ì„œ root_dirë³€ìˆ˜ì— ì €ì¥í•¨.<br>resnet = wespeaker.load_model_local(root_dir)<br>
resnetì´ë¼ëŠ” ë³€ìˆ˜ë¥¼ ì§€ì •í•´ì¤„ê±´ë°, wespeaker ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ load_model_local í•¨ìˆ˜ë¥¼ ì‚¬ìš©í• ê±°ì„. ì´ ë•Œ root_dirì— ìˆëŠ” íŒŒì¼ë“¤ì„ ë¶ˆëŸ¬ì˜¤ê²Œ ë¨.<br>def resnet152(ado, sample_rate=None):<br>
if isinstance(ado, str):<br>
return resnet.recognize(ado)<br>
else:<br>
return recognize(resnet, ado, sample_rate) 	 resnet152ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•´ì£¼ëŠ”ë°, ì´ í•¨ìˆ˜ëŠ” ì…ë ¥ìœ¼ë¡œ adoë¥¼ ë°›ìŒ.<br>
instance(ê°ì²´, íƒ€ì…) : isinstanceí•¨ìˆ˜ëŠ” ì§€ì •ëœ ê°ì²´(ì—¬ê¸°ì—ì„œëŠ” ado)ê°€ ì§€ì •ëœ íƒ€ì…ì´ë©´ trueë¥¼ ë°˜í™˜í•˜ê³  ì•„ë‹ˆë©´ falseë¥¼ ë°˜í™˜í•œë‹¤.<br>
adoê°€ ë¬¸ìì—´ì´ë¼ë©´  resnet.recognize(ado)ë¥¼ ë¦¬í„´í•˜ê³ <br>
ê·¸ë ‡ì§€ ì•Šë‹¤ë©´  recognize(resnet, ado, sample_rate)ì„ ë¦¬í„´í•¨.<br>(recognizeí•¨ìˆ˜ëŠ” ì´ì „ì— ì§€ì •í•´ë‘” í•¨ìˆ˜ì´ë‹¤.)<br>def recognize(model, pcm, sample_rate):
    q = extract_embedding(model, pcm, sample_rate)
    best_score = 0.0
    best_name = ''
    for name, e in model.table.items():
        score = model.cosine_similarity(q, e)
        if best_score &lt; score:
            best_score = score
            best_name = name
        del score
        gc.collect()
    return {'name': best_name, 'confidence': best_score}
<br>resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)<br>
resnet152ë¼ëŠ” í•¨ìˆ˜ì— registerë¼ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€(ëŒ€ì²´?)<br>
lambdaí•¨ìˆ˜ë¥¼ í†µí•´ì„œ resnet152ì—ì„œ registerë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í•  ë•Œ, resnetê°ì²´ì˜ register ë©”ì„œë“œë¥¼ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.<br>
args, kwargs : ëª‡ ê°œì˜ ì¸ìë¥¼ ë°›ì•„ì•¼ í• ì§€ ì •í•  ìˆ˜ ì—†ì„ ë•Œ argsì™€ kwargs(keyword arguments)ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ì¨ì¤Œ. args ì•ì— ë¶™ëŠ”  * ëŠ” ì—¬ëŸ¬ê°œì˜ ì¸ìë¥¼ ë¬¶ì–´ì„œ í•˜ë‚˜ì˜ íŠœí”Œë¡œ ë¬¶ì–´ì£¼ê³  ì´ë¥¼ argsì— í• ë‹¹í•´ì¤€ë‹¤. kwargs ì•ì— ë¶™ëŠ” ** ëŠ” ì—¬ëŸ¬ê°œì˜ í‚¤ì›Œë“œ ì•„ê·œë¨¼íŠ¸ë“¤ì„ ë¬¶ì–´ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ì–´ì¤€ë‹¤. <br>return resnet152<br>
get_resnet152ë¼ëŠ” í•¨ìˆ˜ëŠ” resnet152ë¥¼ ë°˜í™˜í•¨.<br>resnet152 = get_resnet152()
print("INFO: ResNet152 Ready -", resnet152)
<br>ë¶„ì„<br>
resnet152 = get_resnet152()<br>
get_resnet152í•¨ìˆ˜ë¥¼ ê°€ì ¸ì™€ì„œ resnet152í•¨ìˆ˜ì— ì €ì¥í•¨<br>
print("INFO: ResNet152 Ready -", resnet152)<br>
ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•œ ë’¤, resnet152ë¥¼ ì¶œë ¥í•¨.]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240716-ëª¨ê°ì½”-í™œë™-3íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240716 ëª¨ê°ì½” í™œë™ 3íšŒì°¨.md</guid><pubDate>Tue, 30 Jul 2024 04:01:59 GMT</pubDate></item><item><title><![CDATA[20240723 ëª¨ê°ì½” í™œë™ 4íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ëª©í‘œ<br>
1.cnnê³µë¶€ - ì •ì˜ì™€ êµ¬ì¡° ì‚´í´ë³´ê¸°<br>
2.resnetê³µë¶€ - ì •ì˜ì™€ êµ¬ì¡° ì‚´í´ë³´ê¸°<br>ë”¥ ëŸ¬ë‹ : ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì£¼ë¡œ ë‹¤ë£¨ëŠ” aië¶„ì•¼. ì‹¬ì¸µ ì‹ ê²½ë§ì€ ì‹ ê²½ë§ì„ ì—¬ëŸ¬ ê³„ì¸µìœ¼ë¡œ êµ¬ì„±í•œ ê²ƒ.<br>
ê¸°ì¡´ ì‹ ê²½ë§ì˜ í° ë‹¨ì  : ì…ë ¥ ë°ì´í„°ì˜ êµ¬ì¡° ê³ ë ¤ ì•ˆ í•¨. -&gt; ì´ë¯¸ì§€ì™€ ê°™ì€ ê³µê°„ì  êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” ë°ì´í„° ë‹¤ë£¨ê¸° ì í•©í•˜ì§€ ì•ŠìŒ.<br>
ê¸°ì¡´ ì‹ ê²½ë§ì—ì„œì˜ ë‹¨ì (ê³µê°„ì  êµ¬ì¡° ë°ì´í„° ë‹¤ë£¨ê¸° ì–´ë ¤ì›€)ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ cnn ë“±ì¥<br>CNN<br>
í•©ì„±ê³± ì‹ ê²½ë§<br>
-2ì°¨ì› êµ¬ì¡°ë¥¼ ê³ ë ¤í•˜ëŠ” ì‹ ê²½ë§<br>
-ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤ë¡œ ì´ë£¨ì–´ì§„ ë‰´ëŸ°ìœ¼ë¡œ êµ¬ì„±<br>
- ì…ë ¥ë°ì´í„°ë¥¼ ë°›ê³ , ì²˜ë¦¬í•œ í›„ íŠ¹ì •í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•¨.<br>
-ì…ë ¥ ê³„ì¸µì— ë“¤ì–´ì˜¨ ë¯¸ê°€ê³µ ì´ë¯¸ì§€ ë°ì´í„°ì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ëª©ì .<br>
-ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ëŠ” ì¶œë ¥ ê³„ì¸µì˜ ê²°ê³¼ ê°’ í˜•íƒœ(í´ë˜ìŠ¤ ì ìˆ˜ ë³€í™˜ë¨)ë¡œ ì¶œë ¥ë¨.<br>
-ê³„ì¸µì˜ ì¢…ë¥˜<br>
1. ì…ë ¥ì¸µ<br>
- ë¯¸ê°€ê³µ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°›ìŒ.<br>
2. í•©ì„±ê³±ì¸µ<br>
- í•©ì„±ê³± ì—°ì‚°ì„ ìˆ˜í–‰í•¨.<br>
- ì»¤ë„(n  mì˜ í–‰ë ¬)ë¡œ ì´ë¯¸ì§€(ë†’ì´  ë„ˆë¹„)ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ ê²¹ì³ í›‘ëŠ”ë‹¤. ê²¹ì³ì§€ëŠ” ë¶€ë¶„ì˜ ê° ì´ë¯¸ì§€ì™€ ì›ì†Œì˜ ê°’ì„ ê³±í•´ì„œ ëª¨ë‘ ë”í•œ ê°’ì„ ì¶œë ¥í•¨.<br>
- ìŠ¤íŠ¸ë¼ì´ë“œ : ì»¤ë„ì´ ì…ë ¥ì„ í›‘ëŠ”ë°, ì´ ë•Œì˜ ë³´í­ì„ ëœ»í•¨.<br>
- ì´ ë•Œ ì¶œë ¥ë˜ëŠ” ê²ƒ(ì…ë ¥ìœ¼ë¡œë¶€í„° ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ í•©ì„±ê³± ì—°ì‚°ì„ í†µí•´ ë‚˜ì˜¨ ê²°ê³¼)ì€ 'ì¶œë ¥ íŠ¹ì„± ë§µ(output feature map)' ì´ë¼ í•¨.<br>
- CNNì—ì„œëŠ” í•©ì„±ê³± ê³„ì¸µì˜ ì…ì¶œë ¥ ë°ì´í„°ë¥¼ íŠ¹ì„± ë§µ(feature map) ì´ë¼ í•¨.<br>
- <img alt="cnn ì—°ì‚° ë°©ë²•" src="https://ejkiwi.github.io/lib/media/cnn1.png" referrerpolicy="no-referrer"><br>
3.ReLUì¸µ<br>
- ì¸ê³µì‹ ê²½ë§ì—ì„œ ì‚¬ìš©ë˜ëŠ” í™œì„±í™”í•¨ìˆ˜ f(x) = max(0, x) -&gt; ì…ë ¥ê°’ì´ 0ë³´ë‹¤ í¬ë©´ ê·¸ ê°’ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ê³ , 0 ì´í•˜ë©´ 0ì„ ì¶œë ¥.<br>
4. í’€ë§ì¸µ<br>
- íŠ¹ì„± ë§µì„ ë‹¤ìš´ìƒ˜í”Œë§í•˜ì—¬ íŠ¹ì„± ë§µì˜ í¬ê¸°ë¥¼ ì¤„ì„.<br>
- í•©ì„±ê³± ì—°ì‚°ê³¼ ìœ ì‚¬í•¨ (ì»¤ë„ê³¼ ìŠ¤íŠ¸ë¼ì´ë“œ ê°œë…ì´ ì¡´ì¬)<br>
- ìµœëŒ€í’€ë§ : ì»¤ë„ê³¼ ê²¹ì¹˜ëŠ” ì˜ì—­ ì•ˆì—ì„œ ìµœëŒ€ê°’ì„ ì¶”ì¶œ<br>
- í‰ê· í’€ë§ : ì»¤ë„ê³¼ ê²¹ì¹˜ëŠ” ì˜ì—­ ì•ˆì—ì„œ í‰ê· ê°’ì„ ì¶”ì¶œ<br>RESNET<br>
CNNì˜ í•œ ì¢…ë¥˜<br>
-ì‹ ê²½ë§ì˜ ê¹Šì´ê°€ ê¹Šì–´ì§ì— ë”°ë¼ ë°œìƒí•˜ëŠ” í›ˆë ¨ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ 'ì”ì—¬í•™ìŠµ'ì´ë¼ëŠ” ê°œë…ì„ ë„ì…í•¨.<br>
- í›ˆë ¨ ë¬¸ì œ : ê¸°ì¡´ ëª¨ë¸ë“¤ì€ ë ˆì´ì–´ë¥¼ ê¹Šê²Œ ìŒ“ì„ìˆ˜ë¡ ë” ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ê²ƒì´ë¼ê³  ì˜ˆìƒí–ˆì§€ë§Œ ì‹¤ì œë¡œëŠ” 20ì¸µ ì´ìƒë¶€í„° ì„±ëŠ¥ì´ ë‚®ì•„ì§€ëŠ” í˜„ìƒì´ ë°œìƒ.<br>
- ì”ì—¬í•™ìŠµ : ìŠ¤í‚µì—°ê²°(ì…ë ¥ê°’ì´ ì¼ì •ì¸µë“¤ì„ ê±´ë„ˆë›°ì–´ì„œ ì¶œë ¥ì— ë”í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì—­í• ) -&gt; ê¸°ì¡´ì‹ ê²½ë§ì€ kë²ˆì§¸ ì¸µê³¼ (i+1)ë²ˆì§¸ ì¸µì˜ ì—°ê²°ë¡œ ì´ë£¨ì–´ì ¸ìˆëŠ”ë°, resnetì€ (i+r)ì¸µì˜ ì—°ê²°ì„ í—ˆìš©(shortcut connection).<br>
- <img alt="ResNet êµ¬ì¡°" src="https://ejkiwi.github.io/lib/media/resnet.png" referrerpolicy="no-referrer"><br>
-ìµœëŒ€ 152ê°œ ì¸µê¹Œì§€ ìŒ“ì„ ìˆ˜ ìˆê²Œ ë¨.<br>
<img alt="cnn2" src="https://ejkiwi.github.io/lib/media/cnn2.png" referrerpolicy="no-referrer">]]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240723-ëª¨ê°ì½”-í™œë™-4íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240723 ëª¨ê°ì½” í™œë™ 4íšŒì°¨.md</guid><pubDate>Tue, 23 Jul 2024 13:38:23 GMT</pubDate><enclosure url="https://ejkiwi.github.io/lib/media/cnn1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://ejkiwi.github.io/lib/media/cnn1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[20240730 ëª¨ê°ì½” í™œë™ 5íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ëª©í‘œ<br>
1.cnnê³µë¶€ - í•©ì„±ê³± ê³„ì¸µì—ì„œì˜filter, Paddingì— ëŒ€í•´ ë” ì•Œì•„ë³´ê¸°.<br>
2.resnetê³µë¶€ - Residual Blockê³¼ Skip-Connection ì— ëŒ€í•´ ë” ê¹Šì´ ì•Œì•„ë³´ê¸°<br>í•©ì„±ê³± ê³„ì¸µì—ì„œì˜ filter<br>
CNNì—ì„œ filterëŠ” ì»¤ë„(n * mì˜ í–‰ë ¬)ì™€ ê°™ì€ ì˜ë¯¸ì´ë‹¤. (maskë¼ê³ ë„ ë¶ˆë¦°ë‹¤.)<br>
filterë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ì‚¬ì§„ì—ì„œ feature(íŠ¹ì§•)ë¥¼ ë½‘ì•„ë‚´ê¸° ìœ„í•¨ì´ë‹¤.<br>
<br>ì…ë ¥ ë°ì´í„°ì˜ ì „ì²´ ì´ë¯¸ì§€ì—ì„œ, filterë¥¼ í†µí•´ ì²œì œ ì´ë¯¸ì§€ë¥¼ ìˆœí™˜í•˜ë©°, íŠ¹ì • filterëª¨ì–‘ê³¼ ì¼ì¹˜í• ìˆ˜ë¡ ë” í° ê°’ì„ ê°€ì§€ê²Œ ë  ê²ƒì¸ë°, ì´ëŠ” ì „ì²´ ì´ë¯¸ì§€ì„œ íŠ¹ì • filterì™€ ìœ ì‚¬í•œ ëª¨ì–‘ì„ ê°€ì§„ ë¶€ë¶„ì— ëŒ€í•œ featureë“¤ë§Œ ì–»ê²Œ ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. =&gt; íŠ¹ì • filterì— ë¶€í•©í•˜ëŠ” featureì •ë³´ë¥¼ ì–»ëŠ” ê³¼ì •.
<br>Padding<br>
cnnêµ¬ì¡°ì—ì„œ, í•©ì„±ê³±ì¸µì„ ì§€ë‚˜ê²Œ ë˜ë©´, í•©ì„±ê³± ì—°ì‚°ìœ¼ë¡œ ì¸í•´ì„œ Feature Mapì˜ í¬ê¸°ëŠ” ì…ë ¥ë°ì´í„°ë³´ë‹¤ í¬ê¸°ê°€ ì‘ì•„ì§€ê²Œ ëœë‹¤. ì´ë ‡ê²Œ í¬ê¸°ê°€ ì‘ì•„ì§€ëŠ”ê²ƒì„ í”¼í•˜ê¸° ìœ„í•´ì„œ Padding ì´ë¼ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.<br>
<br>zero padding : ì…ë ¥ ë°ì´í„°(ì´ë¯¸ì§€) ì£¼ìœ„ë¥¼ 0ìœ¼ë¡œ ë‘˜ëŸ¬ì£¼ëŠ” paddingì˜ ë°©ë²•ì´ë‹¤.<br>
<img alt="zero padding" src="https://ejkiwi.github.io/lib/media/zero_Padding.png" referrerpolicy="no-referrer">

<br>P : padding layerì˜ ìˆ˜
<br>n : ì´ë¯¸ì§€ì˜ í¬ê¸°ê°€ n * n
<br>f : ì»¤ë„ì˜ í¬ê¸°(filterì˜ í¬ê¸°)ê°€  f * f
<br>(n+2p) * (n+2p) : íŒ¨ë”©ëœ ì´ë¯¸ì§€ì˜ í¬ê¸°
<br>((n + 2p â€“ f + 1) * (n + 2p â€“ f + 1)) :  í•©ì„±ê³±ì¸µì„ ì§€ë‚œ ì¶œë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°


<br>paddingì´ í•„ìš”í•œ ì´ìœ 

<br>ì´ë¯¸ì§€ ë°ì´í„°ì˜ ì¶•ì†Œë¥¼ ë§‰ì„ ìˆ˜ ìˆë‹¤. -  ì—¬ëŸ¬ë²ˆì˜ ê³„ì‚°ì„ ê±°ì³ì•¼ í•˜ëŠ”ë° ì´ˆë°˜ë¶€í„° ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ì•„ì ¸ë²„ë¦°ë‹¤ë©´ í•™ìŠµì„ ë³„ë¡œ í•˜ì§€ ëª»í•˜ê³  ëë‚˜ë²„ë¦´ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— paddingì„ í†µí•´ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆí•´ì¤˜ì•¼í•œë‹¤.
<br>ëª¨ì„œë¦¬ì— ìˆëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶©ë¶„íˆ í™œìš©í•  ìˆ˜ ìˆë‹¤. - paddingì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°, ëª¨ì„œë¥¼ í•™ìŠµí•  ê¸°íšŒê°€ ì ì–´ì§€ê²Œ ëœë‹¤. ë§Œì•½ ì¤‘ìš”í•œ ì •ë³´ê°€ ëª¨ì„œë¦¬ìª½ì— ìˆë‹¤ë©´, ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê¸° ë•Œë¬¸ì— paddingì„ ì‚¬ìš©í•˜ì—¬ ëª¨ì„œë¦¬ì˜ ì •ë³´ë“¤ë„ ì¶©ë¶„íˆ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì–´ì•¼ í•œë‹¤.<br>
<img alt="íŒ¨ë”©ê³¼ ëª¨ì„œë¦¬~" src="https://ejkiwi.github.io/lib/media/CNN_Padding_Edge.png" referrerpolicy="no-referrer">


<br>Valid Paddingê³¼ Same Padding : ê°ê° ìˆœì„œëŒ€ë¡œ íŒ¨ë”©í•˜ì§€ ì•ŠëŠ” ê²ƒ, ì…ë ¥ë°ì´í„°ì™€ ì¶œë ¥ë°ì´í„°ê°€ ë™ì¼í•˜ë„ë¡ í•˜ëŠ” íŒ¨ë”©ì„ ëœ»í•œë‹¤.
<br>Residual Block ê³¼ Skip-Connection<br>
Residual Blockì€ ì¸µì´ ê¹Šì–´ì§€ë”ë¼ë„ ì„±ëŠ¥ì´ ë’¤ë–¨ì–´ì§€ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•´ ì œì‹œëœ ê²ƒ.<br>
Residual ì€ "ì”ì—¬" ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆëŠ”ë°, xë¥¼ ì…ë ¥ H(x)ë¥¼ xì˜ ë¶„í¬ë¡œ ê°€ì •í•˜ë©´ residualì€ ìµœì¢…ìœ¼ë¡œ êµ¬í•˜ê³ ì í•˜ëŠ” H(x)ì™€ xì˜ ì°¨ì´ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.<br>
ì¦‰, Residual = R(x) = H(x) - x ê°€ ë˜ë©° H(x) = R(x) + x ë¡œ ì •ë¦¬ê°€ëŠ¥í•˜ë‹¤. <br>
<br><img alt="residualblock" src="https://ejkiwi.github.io/lib/media/residual%20block.png" referrerpolicy="no-referrer">
<br>ìœ„ ì‹ ê²½ë§ì¸µì—ì„œëŠ” F(x)rê°€ R(x)ì˜ ì—­í• ì„ í•˜ê¸° ë•Œë¬¸ì— Residual Blockì´ë¼ ë¶ˆë¦¬ê²Œ ëœë‹¤.<br>
Residual Blockì€ ê·¸ë ˆë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œë¥¼ ì•½í™”ì‹œí‚¤ê³ , ì´ì— ë”°ë¼ ì‹ ê²½ë§ì˜ ê¹Šì´ê°€ ê¹Šì–´ì ¸ë„ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ì§€ ì•Šê²Œ ë˜ëŠ” ê²ƒ.
<br>ê·¸ë ˆë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œ<br>
- ì‹ ê²½ë§ì„ í•™ìŠµì‹œëŠ” ê³¼ì •ì—ì„œ -&gt; ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì¶œë ¥ì¸µì—ì„œ ì…ë ¥ì¸µìœ¼ë¡œ ì†ì‹¤í•¨ìˆ˜ì— ëŒ€í•œ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ì „íŒŒí•˜ê³ , ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•´ ì´ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ëŠ” ë‹¨ê³„ë¥¼ ê±°ì¹˜ê²Œ ë¨.<br>
-  ì´ ë•Œ ì‹ ê²½ë§ì˜ í•˜ìœ„ì¸µìœ¼ë¡œ ì§„í–‰ë ìˆ˜ë¡ ê·¸ë ˆë””ì–¸íŠ¸ê°€ ì ì  ì‘ì•„ì§€ê²Œ ë˜ëŠ” ë¬¸ì œê°€ ê·¸ë ˆë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œì´ë‹¤.<br>
residual blockì—ì„œëŠ” x, x+1, x+2 ì¸µì´ ìˆë‹¤ê³  í•  ë•Œ, x+2ì¸µì€ x+1ì¸µë¿ë§Œ ì•„ë‹ˆë¼ xë¡œë¶€í„°ë„ ì •ë³´ë¥¼ ë°›ì„ ìˆ˜ ìˆê²Œ ëœë‹¤. ë”°ë¼ì„œ ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì´ ì‹¤í–‰ë  ë•Œ ê·¸ë ˆë””ì–¸íŠ¸ê°€ ì‘ì•„ì§€ëŠ”ê²ƒì„ ì–´ëŠì •ë„ ë§‰ì•„ì£¼ëŠ” íš¨ê³¼ê°€ ë°œìƒí•œë‹¤.<br>
ì´ëŸ¬í•œ residual blockì˜ ë°©ì‹ì„ í•˜ë‚˜ì˜ í•©ì„±ê³±ì¸µì„ ê¸°ì¤€ìœ¼ë¡œ ì‚´í´ë³´ì•˜ì„ ë•Œ,<br>
í•œ ì¸µì˜ ì…ë ¥ê°’ì„ ì¶œë ¥ê°’ê³¼ í•©ì³ì„œ ë‹¤ìŒ ì¸µìœ¼ë¡œ ë„˜ê²¨ì£¼ëŠ” ë°©ì‹ì´ ê·¸ ì¸µì˜ ì…ë ¥ê°’ì´ í•´ë‹¹ ì¸µì„ í†µê³¼í•˜ì§€ ì•Šê³  ë‹¤ìŒ ì¸µìœ¼ë¡œ ë„˜ì–´ê°€ëŠ” ê²ƒê³¼ ê°™ê¸° ë•Œë¬¸ì— Skip Connectionì´ë¼ ë¶€ë¥´ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.<br>
ì¦‰, Residual Blockì˜ í•µì‹¬ì€ Skip Connectionì´ë¼ í•  ìˆ˜ ìˆë‹¤.
]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240730-ëª¨ê°ì½”-í™œë™-5íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240730 ëª¨ê°ì½” í™œë™ 5íšŒì°¨.md</guid><pubDate>Wed, 31 Jul 2024 12:40:41 GMT</pubDate><enclosure url="https://ejkiwi.github.io/lib/media/zero_Padding.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://ejkiwi.github.io/lib/media/zero_Padding.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[20240806 ëª¨ê°ì½” í™œë™ 6íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ëª©í‘œ<br>
CNN ì‹¤ìŠµ - MNIST ì´ë¯¸ì§€ ë¶„ë¥˜ ( RESNETì€ 7íšŒì°¨ì— ì§„í–‰í•  ì˜ˆì • )<br>import torch #pytorch ê°€ì ¸ì˜¤ê¸°
<br>ë°ì´í„° ê°€ì ¸ì˜¤ê¸°<br>#ë°ì´í„°ì…‹ë¶ˆëŸ¬ì˜¤ê³  í…ì„œë¡œ ë°”ê¿”ì£¼ê¸°

from torchvision import datasets #ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê³ 

from torchvision.transforms import ToTensor #í…ì„œë¡œ ë°”ê¿”ì£¼ê¸°

  

#datasetsì—ì„œ MNIST ê°€ì ¸ì™€ì„œ í›ˆë ¨ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ë°ì´í„° ê°€ì ¸ì™€ì£¼ê¸°.

#datasets.MNIST(root - ë°ì´í„°ê°€ ì €ì¥ë  ê²½ë¡œ, train - trainì´ true ì´ë©´ train dataì´ê³  falseë©´ test data, download - ë°ì´í„° ì—†ìœ¼ë©´ ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œí•´ì¤Œ , transform - transformì„ ToTensorë¡œ ì§€ì •í•´ì£¼ì§€ ì•Šìœ¼ë©´ í…ì„œì˜ í˜•ì‹ì´ ì•„ë‹Œ, PILì´ë¯¸ì§€ë¡œ ë°ì´í„°ê°€ ê°€ì ¸ì™€ì§€ê²Œ ëœë‹¤)

  

train_data = datasets.MNIST(

&nbsp; &nbsp; root = "data",

&nbsp; &nbsp; train = True, #train dataë¥¼ ë‹¤ìš´ë¡œë“œ

&nbsp; &nbsp; transform = ToTensor(),

&nbsp; &nbsp; download = True

)

test_data = datasets.MNIST(

&nbsp; &nbsp; root = 'data',

&nbsp; &nbsp; train = False, #test dataë¥¼ ë‹¤ìš´ë¡œë“œ

&nbsp; &nbsp; transform = ToTensor()

)
<br>ë°ì´í„° í™•ì¸í•˜ê¸°<br>#í•™ìŠµë°ì´í„° í™•ì¸

print(train_data)

print(train_data.data.size())

# ë°ì´í„°ì…‹ì˜ ì´ë¦„ì€ MNIST

# ë°ì´í„°ì˜ ìˆ˜ëŠ” 60000ê°œ

# í›ˆë ¨ë°ì´í„°

# StandardTransform(ë°ì´í„°ì…‹ì— ì¼ê´€ë˜ê²Œ ì ìš©ë˜ëŠ” ë³€í™˜ì˜ í‘œì¤€ì„ ì •ì˜) -&gt; Transform: ToTensor() #ì´ë¯¸ì§€ ë°ì´í„°ë“¤ì„ ëª¨ë‘ ì¼ê´€ë˜ê²Œ í…ì„œ í˜•íƒœë¡œ ë³€í™˜í•˜ê² ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸.


#í…ŒìŠ¤íŠ¸ë°ì´í„° í™•ì¸

print(test_data)

print(test_data.data.size())

#ë°ì´í„°ì˜ ìˆ˜ê°€ 10000 ì¸ ê²ƒê³¼ í…ŒìŠ¤íŠ¸ë°ì´í„°ë¼ëŠ” ê²ƒì„ ì œì™¸í•˜ë©´ ë‚˜ë¨¸ì§€ ì†ì„±ì€ í•™ìŠµë°ì´í„°ì™€ ë™ì¼í•¨.
<br>#ë°ì´í„° ì‹œê°ì ìœ¼ë¡œ í™•ì¸

import matplotlib.pyplot as plt #ì‹œê°ì  í™•ì¸ì„ ìœ„í•´ matplotlibì„ ì‚¬ìš©.

fig, ax = plt.subplots() # fig -&gt; ë°ì´í„°ê°€ ë‹´ê¸°ëŠ” í”„ë ˆì„ / ax -&gt; ì‹¤ì œ ë°ì´í„°ê°€ ê·¸ë ¤ì§€ëŠ” ìº”ë²„ìŠ¤

ax.imshow(train_data.data[0], cmap='gray') #ë°ì´í„°ì˜ ëª¨ìŠµ



#ì´ë¯¸ì§€ ìœ„ì— ê° í”½ì…€ ê°’ì„ í‘œì‹œí•´ì„œ ë‚˜íƒ€ë‚´ë³´ê¸°

for i in range(train_data.data[0].shape[0]): # iì™€jëŠ” í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•  ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ê¸° ìœ„í•¨.

&nbsp; for j in range(train_data.data[0].shape[1]):

&nbsp; &nbsp; c = 1 if train_data.data[0][i, j].item() &lt; 125 else 0 # ì´ë¯¸ì§€ì˜ ê° í”½ì…€ ê°’( train_data.data[0][i,j].item() )ì´ 125ë³´ë‹¤ ì‘ìœ¼ë©´ c = 1 í°ìƒ‰ì„ ì‚¬ìš©, í¬ë©´ c = 0 ê²€ì • ì‚¬ìš©.

&nbsp; &nbsp; ax.text(j, i, str(train_data.data[0][i, j].item()), color=(c, c, c), ha='center', va='center', fontsize=5) # text()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìœ„ì— í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°

  

plt.title("%i" % train_data.targets[0])

plt.show
<br><img alt="mnist_1" src="https://ejkiwi.github.io/lib/media/MNIST.png" referrerpolicy="no-referrer"><br>ë°ì´í„° ì¤€ë¹„í•˜ê¸°<br>from torch.utils.data import DataLoader
# DataLoader -&gt; &nbsp;ë°ì´í„°ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ í˜•íƒœë¡œ ë§Œë“¤ì–´ì„œ ìš°ë¦¬ê°€ ì‹¤ì œë¡œ í•™ìŠµí•  ë•Œ ì´ìš©í•  ìˆ˜ ìˆë„ë¡ í•¨.
#DataLoader(dataset ë°ì´í„° , batch_size=1 í•œ ë²ˆì˜ ë°°ì¹˜ ì•ˆì— ìˆëŠ” ìƒ˜í”Œ ì‚¬ì´ì¦ˆ, shuffle=False ë°ì´í„°ì…‹ì„ ì„ì–´ì„œ ë°ì´í„°ê°€ í•™ìŠµë˜ëŠ” ìˆœì„œë¥¼ ë°”ê¿ˆ, num_workers=0 ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” í”„ë¡œì„¸ì„œì˜ ìˆ˜. í•˜ë‚˜ ë” ì¶”ê°€í•˜ë©´ 20%ì •ë„ ì†ë„ê°€ ë¹¨ë¼ì§.)
#ë°°ì¹˜ í•™ìŠµ -&gt; ì „ì²´ ë°ì´í„°ë¥¼ në“±ë¶„ í•˜ì—¬ í•™ìŠµ.

loaders = {

&nbsp; &nbsp; 'train' : torch.utils.data.DataLoader(train_data,

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; batch_size=100,

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; shuffle=True,

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_workers=1),

&nbsp; &nbsp; 'test' : torch.utils.data.DataLoader(test_data,

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;batch_size=100,

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;shuffle=True,

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;num_workers=1)

}

loaders
<br>CNN ëª¨ë¸ ì„¤ì •í•˜ê¸°<br>class CNN(torch.nn.Module):

  

&nbsp; def __init__(self):

&nbsp; &nbsp; super(CNN, self).__init__()

&nbsp; &nbsp; self.layer1 = torch.nn.Sequential(

&nbsp; &nbsp; &nbsp; &nbsp; torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2), #ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(í•©ì„±ê³±ì¸µ) #1ì°¨ì›(1ê°œì±„ë„) ë°ì´í„°ë¥¼ ë°›ì•„ 16ê°œì˜ feature(16ê°œì˜ì±„ë„)ë¡œ ë‚˜ëˆ„ê²Ÿë‹¤!!ì„.

&nbsp; &nbsp; &nbsp; &nbsp; torch.nn.ReLU(), #ReLUì¸µ

&nbsp; &nbsp; &nbsp; &nbsp; torch.nn.MaxPool2d(kernel_size=2, stride=2)) #í’€ë§ì¸µ

&nbsp; &nbsp; self.layer2 = torch.nn.Sequential(

&nbsp; &nbsp; &nbsp; &nbsp; torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),

&nbsp; &nbsp; &nbsp; &nbsp; torch.nn.ReLU(),

&nbsp; &nbsp; &nbsp; &nbsp; torch.nn.MaxPool2d(kernel_size=2, stride=2))
&nbsp; &nbsp; &nbsp; &nbsp; 
&nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; # layer 1, layer2 ì¸µê¹Œì§€ëŠ” ì´ë¯¸ì§€ë¥¼ í˜•ìƒìœ¼ë¡œ ë¶„í• í•˜ê³  ë¶„ì„í•˜ëŠ” ë¶€ë¶„
&nbsp; &nbsp; &nbsp; &nbsp; # ë‹¤ìŒ fc ì¸µì—ì„œëŠ” ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ ì˜ˆì¸¡í•˜ëŠ” ë¶€ë¶„.
&nbsp; &nbsp; &nbsp; &nbsp; 

&nbsp; &nbsp; self.fc = torch.nn.Linear(32 * 7 * 7, 10, bias=True) #32*7*7ë§Œí¼ì˜ ì…ë ¥ì„ linearë ˆì´ì–´ì— ì˜í•´ ê³„ì‚°ë˜ê²Œ í•´ì„œ... 10ê°œì˜ ì¶œë ¥( MNIST ì´ë¯¸ì§€ë¥¼ 0ë¶€í„° 9ê¹Œì§€ ë¶„ë¥˜í•´ì•¼í•˜ê¸°ë•Œë¬¸ )ì´ ë‚˜ì˜¤ë„ë¡ í•¨.

&nbsp; &nbsp; torch.nn.init.xavier_uniform_(self.fc.weight) # ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™” ( ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµ ì „ì— ì ì ˆí•œ ê°’ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê³¼ì • )



&nbsp; &nbsp; # __init__ì—ì„œëŠ” í•„ìš”í•œ ë ˆì´ì–´ë“¤ì„ ì •ì˜ë‚´ë ¸ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ.
&nbsp; &nbsp; # ì•„ë˜ forward(ì–˜ê°€ ì‹¤ì œì ì¸ ëª¨ë¸ì˜ í˜•íƒœê°€ ë¨)ì—ì„œ ì‚¬ìš©í•œë‹¤.

&nbsp; def forward(self, x): #ìˆœì „íŒŒ #ìˆœì „íŒŒë§Œ ì§€ì •í•´ì£¼ì–´ë„ pytorchì—ì„œëŠ” ì—­ì „íŒŒ ê³¼ì •ì„ ë§¤ìš° ì‰½ê²Œ í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤.

&nbsp; &nbsp; out = self.layer1(x)

&nbsp; &nbsp; out = self.layer2(out)

&nbsp; &nbsp; out = out.view(out.size(0), -1) #  view() í•¨ìˆ˜ëŠ” í…ì„œì˜ í¬ê¸°ë¥¼ ë³€ê²½í•˜ëŠ” ë° ì‚¬ìš© # ë°ì´í„°ë¥¼ ì™„ì „ ì—°ê²°(fc) ì¸µì— ì „ë‹¬í•˜ê¸° ìœ„í•´ 2ì°¨ì› ë˜ëŠ” 3ì°¨ì› í…ì„œë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ í‰íƒ„í™” í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•¨.
&nbsp; &nbsp; out = self.fc(out)

&nbsp; &nbsp; return out
<br>model = CNN()

model
<br>CNN(<br>
(layer1): Sequential(<br>
(0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))<br>
(1): ReLU()<br>
(2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>
)<br>
(layer2): Sequential(<br>
(0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))<br>
(1): ReLU()<br>
(2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br>
)<br>
(fc): Linear(in_features=1568, out_features=10, bias=True)<br>
)<br><br>í•™ìŠµí•˜ê¸°<br>learning_rate = 0.01 # íŒŒë¼ë¯¸í„°ë¥¼ ì–¼ë§ˆë‚˜ ì—…ë°ì´íŠ¸í•  ê²ƒì¸ì§€ë¥¼ ê²°ì •. í•™ìŠµë¥ , step size. ë„ˆë¬´ í¬ì§€ë„ ì‘ì§€ë„ ì•Šì•„ì•¼ í•¨.

loss_func = torch.nn.CrossEntropyLoss() # ëª¨ë¸ ì˜ˆì¸¡ê³¼ ì‹¤ì œê°’ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ì†ì‹¤í•¨ìˆ˜.

optimizer = &nbsp;torch.optim.Adam(model.parameters(), lr=learning_rate) # ì†ì‹¤í•¨ìˆ˜ë¥¼ í†µí•´ ë‚˜ì˜¨ ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•

training_epochs = 10 # ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí•  ê²ƒì¸ì§€ ê²°ì •.
<br># ë°˜ë³µì˜ íšŸìˆ˜ëŠ” epochê³¼ batchì˜ í¬ê¸°ì— ë”°ë¼ ê²°ì •

total_batch = len(loaders['train'])

for epoch in range(training_epochs):

&nbsp; avg_cost = 0

&nbsp; for X, Y in loaders['train']:

&nbsp; &nbsp; optimizer.zero_grad() # í•™ìŠµì—ì„œ, ì—­ì „íŒŒë¥¼ ê±°ì¹  ë•Œ ë§ˆë‹¤ ê° .grad ê°’ì— ë³€í™”ë„ê°€ ì €ì¥ì´ ë˜ëŠ”ë°,  ì´ì–´ì§€ëŠ” ë‹¤ìŒ í•™ìŠµì—ì„œ .gradì˜ ê°’ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”ì‹œì¼œì£¼ì§€ ì•Šìœ¼ë©´ ì´ì „ì— ì €ì¥ëœ ë³€í™”ë„ ê°’ì´ ë‹¤ìŒ í•™ìŠµì— ì˜í–¥ì„ ì£¼ê¸° ë•Œë¬¸ì— ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•˜ê¸° í˜ë“¤ë‹¤. ê·¸ë˜ì„œzero_gradë¥¼ í†µí•´ .grad ì˜ ê°’ë“¤ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”ì‹œì¼œì¤€ë‹¤.

&nbsp; &nbsp; pred = model(X) #ìˆœì „íŒŒ

&nbsp; &nbsp; cost = loss_func(pred, Y) #ì†ì‹¤í•¨ìˆ˜ê³„ì‚°

&nbsp; &nbsp; cost.backward() #ì—­ì „íŒŒ

&nbsp; &nbsp; optimizer.step() # ì—­ì „íŒŒ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ëœ ë³€í™”ë„ë¡œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •

  

&nbsp; &nbsp; avg_cost += cost / total_batch

  

&nbsp; print('[Epoch: {:&gt;4}] cost = {:&gt;.9}'.format(epoch + 1, avg_cost))
&nbsp; # `epoch + 1` ê°’ì„ ìµœì†Œ 4ì¹¸ì˜ ë„ˆë¹„ë¡œ ì˜¤ë¥¸ìª½ ì •ë ¬í•˜ì—¬ ì¶œë ¥
&nbsp; # `avg_cost` ê°’ì„ ìµœì†Œ 9ìë¦¬ê¹Œì§€ ë‚˜íƒ€ë‚´ì–´ ì˜¤ë¥¸ìª½ ì •ë ¬í•˜ì—¬ ì¶œë ¥

print('Learning Finished....&gt;_&lt;')
<br>[Epoch: 1] cost = 0.0461711548<br>
[Epoch: 2] cost = 0.0472225286<br>
[Epoch: 3] cost = 0.0413064063<br>
[Epoch: 4] cost = 0.0417594947<br>
[Epoch: 5] cost = 0.0395734794<br>
[Epoch: 6] cost = 0.0441303253<br>
[Epoch: 7] cost = 0.0408433564<br>
[Epoch: 8] cost = 0.043582622<br>
[Epoch: 9] cost = 0.0441764817<br>
[Epoch: 10] cost = 0.0412645154<br>
Learning Finished....&gt;_&lt;]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240806-ëª¨ê°ì½”-í™œë™-6íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240806 ëª¨ê°ì½” í™œë™ 6íšŒì°¨.md</guid><pubDate>Wed, 07 Aug 2024 13:56:13 GMT</pubDate><enclosure url="https://ejkiwi.github.io/lib/media/MNIST.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://ejkiwi.github.io/lib/media/MNIST.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[20240813 ëª¨ê°ì½” í™œë™ 7íšŒì°¨]]></title><description><![CDATA[ 
 <br>ì˜¤ëŠ˜ì˜ëª©í‘œ<br>
RESNET ì‹¤ìŠµ - CIFAR10 ì´ë¯¸ì§€ ë¶„ë¥˜<br>
ì–‘ìí™” ê³µë¶€<br>#í•„ìš”í•œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°

import torch
import torch.nn as nn #ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë ˆì´ì–´ ì œê³µ -&gt; ëª¨ë¸ ë§Œë“¤ê¸° ë„ìš°ë¯¸!
import torch.nn.functional as F #í™œì„±í™” í•¨ìˆ˜, ì†ì‹¤í•¨ìˆ˜ ë“±ì„ í•¨ìˆ˜ í˜•íƒœë¡œ ì œê³µ.
import torch.backends.cudnn as cudnn
<br>ëª¨ë¸ë§<br>#BasicBlock í´ë˜ìŠ¤ ì •ì˜  
  
class BasicBlock(nn.Module): # nn.Module ìƒì†ë°›ê¸°  
    def __init__(self, in_planes, planes, stride = 1):  
        super(BasicBlock, self).__init__() #BasicBlockì˜ ë¶€ëª¨í´ë˜ìŠ¤ì¸ nn.Moduleì˜ __init__í•¨ìˆ˜ë¥¼ ë¨¼ì € í˜¸ì¶œí•´ì„œ ì‚¬ìš©.  
                  
        #conv1ê³¼ conv2 ì„¤ì •  
        #2D ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì„¤ì •  
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False) # in_planes ì…ë ¥ì±„ë„ ìˆ˜ / planes ì¶œë ¥ì±„ë„ ìˆ˜ / kernel_size 3*3 í•„í„°(ì»¤ë„) ì‚¬ìš© / stride (ì»¤ë„ë¡œ í›‘ì„ ë•Œì˜ ë³´í­) ê¸°ë³¸ê°’ì€ 1 / padding íŒ¨ë”©ì˜ í¬ê¸° 1 / bias = False ë°”ì´ì–´ìŠ¤(ì¶œë ¥ê°’ì„ ì¡°ì ˆí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ”  ê°’) ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê² ë‹¤. -&gt; ë°”ë¡œ ë‹¤ìŒ ì¤„ì˜ ì½”ë“œ(ë°°ì¹˜ì •ê·œí™”)ì—ì„œ ë°”ì´ì–´ìŠ¤ì˜ ì—­í• ì„ í•´ì£¼ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì—ì„  ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.  
        #ë°°ì¹˜ ì •ê·œí™” ì„¤ì •  
        self.bn1 = nn.BatchNorm2d(planes) # planes ë°°ì¹˜ì •ê·œí™”ë¥¼ ì ìš©í•  ì±„ë„ì˜ ìˆ˜. ì•ì˜ ì¶œë ¥ ì±„ë„ì˜ ìˆ˜ì™€ ë™ì¼í•´ì•¼í•¨(ë‹¹ì—°í•¨)  
  
        #2D ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì„¤ì •  
        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)  
        #ë°°ì¹˜ ì •ê·œí™” ì„¤ì •  
        self.bn2 = nn.BatchNorm2d(planes)  
                    
# shortcut ì„¤ì • -&gt; `H(x) = R(x) + x`ì—ì„œì˜ xë¥¼ ìœ„í•œ ì‘ì—…  
        self.shortcut = nn.Sequential() # nn.Sequential : pytorchì—ì„œ ì—¬ëŸ¬ ë ˆì´ì–´ë“¤ì„ ìˆœì„œëŒ€ë¡œ ìŒ“ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ # xë¥¼ ê·¸ëŒ€ë¡œ ë”í•  ìˆ˜ ìˆëŠ” ê²½ìš°  
        if stride != 1: #strideì˜ ê°’ì´ 1ì¸ê²½ìš°(ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì±„ë„ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš° = xë¥¼ ê·¸ëŒ€ë¡œ ë”í•  ìˆ˜ ì—†ëŠ” ê²½ìš°)   
self.shortcut = nn.Sequential(  
                nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),  
                nn.BatchNorm2d(planes)  
            ) # nn.Sequentialì„ ì‚¬ìš©í•´ì„œ Conv2dì™€ BatchNormë ˆì´ì–´ë“¤ì„ ì´ì–´ì¤¬ìŒ  
                  
#ìˆœì „íŒŒ í•¨ìˆ˜ # __init__ì—ì„œ ì„¤ì •í•´ë’€ë˜ ê±° ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„.  
    def forward(self,x):  
        out = F.relu(self.bn1(self.conv1(x))) #conv1 ê±°ì¹˜ê³ , reluí•¨ìˆ˜ ê±°ì¹˜ê¸°  
        out = self.bn2(self.conv2(out)) #ê·¸ë‹¤ìŒ conv2 ê±°ì¹˜ê¸°  
        out += self.shortcut(x) # resnetì˜ í•µì‹¬ì¸ skip connection : H(x) = R(x) + x
<br>#ResNet í´ë˜ìŠ¤ ì •ì˜  
class ResNet(nn.Module):  
    def __init__(self, block, num_blocks, num_classes = 10):  
        super(ResNet, self).__init__() #ResNetì˜ ë¶€ëª¨í´ë˜ìŠ¤ì¸ nn.Moduleì˜ __init__í•¨ìˆ˜ë¥¼ ë¨¼ì € í˜¸ì¶œí•´ì„œ ì‚¬ìš©.  
        self.in_planes = 64 # ì…ë ¥ ì±„ë„ ìˆ˜ 64        # 2D ì»¨ë³¼ë£¨ì…˜ë ˆì´ì–´ ì„¤ì •  
        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1, bias = False) # ì…ë ¥ì±„ë„ ìˆ˜ 3 / ì¶œë ¥ì±„ë„ ìˆ˜ 64 / kernel_size 3*3 í•„í„°(ì»¤ë„) ì‚¬ìš© / stride (ì»¤ë„ë¡œ í›‘ì„ ë•Œì˜ ë³´í­) 1 / padding íŒ¨ë”©ì˜ í¬ê¸° 1 / bias = False ë°”ì´ì–´ìŠ¤(ì¶œë ¥ê°’ì„ ì¡°ì ˆí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ”  ê°’) ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê² ë‹¤.  
        # ë°°ì¹˜ì •ê·œí™” ì„¤ì •  
        self.bn1 = nn.BatchNorm2d(64) # ë°°ì¹˜ì •ê·œí™”ë¥¼ ìœ„í•´ ì‚¬ìš©í•  ì±„ë„ ìˆ˜ = ì´ì „ ì±„ë„ì—ì„œì˜ ì¶œë ¥ ì±„ë„ ìˆ˜ = 64        # ë ˆì´ì–´ë¸”ë¡ ì„¤ì •(ê° ë¸”ë¡ì€ ì•ì„œ ì •ì˜í•œ BASIC BLOCKìœ¼ë¡œ êµ¬ì„±ë ê±°ì„. ì¸ì block ìë¦¬ì—, BasicBlockì´ ë“¤ì–´ê°ˆê±°ë‹ˆê¹Œì•„ì•„ì•„~~)  
        # _make_layer() : (ë¸”ë¡ì˜ ì¢…ë¥˜, ì¶œë ¥ ì±„ë„ ìˆ˜, ìŒ“ì„ ë¸”ëŸ­ì˜ ìˆ˜, ë ˆì´ì–´ì˜ ì²« ë¸”ëŸ­ì—ì„œ ì‚¬ìš©í•  strideì˜ ê°’)  
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride = 1) #  
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride = 2)  
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride = 2)  
        # self._make_layer()ì—ì„œ selfëŠ” í˜„ì¬ í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ë¦¬í‚´.  
        # í´ë˜ìŠ¤ ì˜ˆì¸¡ê°’ ê³„ì‚°  
        self.linear = nn.Linear(512, num_classes) # ì…ë ¥ ì±„ë„ ìˆ˜ 512, ì¶œë ¥ ì±„ë„ ìˆ˜ num_classes        # _make_layer í•¨ìˆ˜ ì„¤ì •  
    def _make_layer(self, block, planes, num_blocks, stride):  
        strides = [stride] + [1] * (num_blocks -1) # stride ê°’ ì„¤ì • # ì²« ë²ˆì§¸ ë¸”ë¡ì˜ strideëŠ” ì§€ì •ëœ ê°’ì„ ì‚¬ìš©í•˜ê³  ì´í›„ ë¸”ëŸ­ë“¤ì€ stride = 1ì´ ëœë‹¤.  
        layers = [] # ë¸”ëŸ­ì„ ë‹´ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±  
        for stride in strides:  
            layers.append(block(self.in_planes, planes, stride)) # ì…ë ¥ ì±„ë„ ìˆ˜ self.in_planes, ì¶œë ¥ ì±„ë„ ìˆ˜ planes, ìŠ¤íŠ¸ë¼ì´ë“œ ê°’ stride            self.in_planes = planes # ì±„ë„ ìˆ˜ ë³€ê²½í•´ì£¼ê¸°(ë‹¤ìŒ ë ˆì´ì–´ë¥¼ ìœ„í•´)  
        return nn.Sequential(*layers) # ìƒì„±í•œ ë¸”ë¡ë“¤ì„ í•˜ë‚˜ì˜ ë ˆì´ì–´ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜.  
    # ìˆœì „íŒŒ í•¨ìˆ˜ # __init__ ì„¤ì •í•´ë’€ë˜ê±°ë‘ _make_layer í•¨ìˆ˜ ë§Œë“  ê±° ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„.  
    def forward(self, x):  
        out = F.relu(self.bn1(self.conv1(x)))  
        out = self.layer1(out)  
        out = self.layer2(out)  
        out = self.layer3(out)  
        out = self.layer4(out)  
        out = F.avg_pool2d(out, 4) # í’€ë§ì¸µ  
        out = out.view(out.size(0),-1) # í…ì„œì˜ ì°¨ì› ë³€ê²½  
        out = self.linear(out) #ì™„ì „ ì—°ê²°ì¸µ  
        return out
<br># ResNet 18 í•¨ìˆ˜ ì •ì˜  
def ResNet18():  
    return ResNet(BasicBlock, [2,2,2,2])
<br>ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°<br>import torchvision
import torchvision.transforms as transforms


transform_train = transforms.Compose([
&nbsp; &nbsp; transforms.RandomCrop(32, padding=4),
&nbsp; &nbsp; transforms.RandomHorizontalFlip(),
&nbsp; &nbsp; transforms.ToTensor(),
])


transform_test = transforms.Compose([
&nbsp; &nbsp; transforms.ToTensor(),
])

  
train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)


train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)

<br>í•™ìŠµì‹œí‚¤ê¸°<br>device = 'cuda'
net = ResNet18()
net = net.to(device)
learning_rate = 0.1
file_name = 'resnet18_cifar10.pth'
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)


def train(epoch):
&nbsp; &nbsp; print('\n[ Train epoch: %d ]' % epoch)
&nbsp; &nbsp; net.train()
&nbsp; &nbsp; train_loss = 0
&nbsp; &nbsp; correct = 0
&nbsp; &nbsp; total = 0

&nbsp; &nbsp; for batch_idx, (inputs, targets) in enumerate(train_loader):
&nbsp; &nbsp; &nbsp; &nbsp; inputs, targets = inputs.to(device), targets.to(device)
&nbsp; &nbsp; &nbsp; &nbsp; optimizer.zero_grad()

&nbsp; &nbsp; &nbsp; &nbsp; outputs = net(inputs)
&nbsp; &nbsp; &nbsp; &nbsp; loss = criterion(outputs, targets)
&nbsp; &nbsp; &nbsp; &nbsp; loss.backward()

&nbsp; &nbsp; &nbsp; &nbsp; optimizer.step()
&nbsp; &nbsp; &nbsp; &nbsp; train_loss += loss.item()
&nbsp; &nbsp; &nbsp; &nbsp; _, predicted = outputs.max(1)

&nbsp; &nbsp; &nbsp; &nbsp; total += targets.size(0)
&nbsp; &nbsp; &nbsp; &nbsp;  current_correct = predicted.eq(targets).sum().item()
&nbsp; &nbsp; &nbsp; &nbsp; correct += current_correct
&nbsp; &nbsp; &nbsp; &nbsp; if batch_idx % 100 == 0:

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print('\nCurrent batch:', str(batch_idx))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print('Current batch average train accuracy:', current_correct / targets.size(0))
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print('Current batch average train loss:', loss.item() / targets.size(0))

&nbsp; &nbsp; print('\nTotal average train accuarcy:', correct / total)
&nbsp; &nbsp; print('Total average train loss:', train_loss / total)


def test(epoch):
&nbsp; &nbsp; print('\n[ Test epoch: %d ]' % epoch)
&nbsp; &nbsp; net.eval()
&nbsp; &nbsp; loss = 0
&nbsp; &nbsp; correct = 0
&nbsp; &nbsp; total = 0

  
&nbsp; &nbsp; for batch_idx, (inputs, targets) in enumerate(test_loader):
&nbsp; &nbsp; &nbsp; &nbsp; inputs, targets = inputs.to(device), targets.to(device)
&nbsp; &nbsp; &nbsp; &nbsp; total += targets.size(0)


&nbsp; &nbsp; &nbsp; &nbsp; outputs = net(inputs)
&nbsp; &nbsp; &nbsp; &nbsp; loss += criterion(outputs, targets).item()


&nbsp; &nbsp; &nbsp; &nbsp; _, predicted = outputs.max(1)
&nbsp; &nbsp; &nbsp; &nbsp; correct += predicted.eq(targets).sum().item()


&nbsp; &nbsp; print('\nTotal average test accuarcy:', correct / total)
&nbsp; &nbsp; print('Total average test loss:', loss / total)


&nbsp; &nbsp; state = {
&nbsp; &nbsp; &nbsp; &nbsp; 'net': net.state_dict()
&nbsp; &nbsp; }
&nbsp; &nbsp; if not os.path.isdir('checkpoint'):
&nbsp; &nbsp; &nbsp; &nbsp; os.mkdir('checkpoint')
&nbsp; &nbsp; torch.save(state, './checkpoint/' + file_name)
&nbsp; &nbsp; print('Model Saved!')



import time

def adjust_learning_rate(optimizer, epoch):
&nbsp; &nbsp; lr = learning_rate
&nbsp; &nbsp; if epoch &gt;= 50:
&nbsp; &nbsp; &nbsp; &nbsp; lr /= 10
&nbsp; &nbsp; if epoch &gt;= 100:
&nbsp; &nbsp; &nbsp; &nbsp; lr /= 10
&nbsp; &nbsp; &nbsp; &nbsp; 
&nbsp; &nbsp; for param_group in optimizer.param_groups:
&nbsp; &nbsp; &nbsp; &nbsp; param_group['lr'] = lr
  
start_time = time.time()

for epoch in range(0, 150):
&nbsp; &nbsp; adjust_learning_rate(optimizer, epoch)
&nbsp; &nbsp; train(epoch)
&nbsp; &nbsp; test(epoch)
&nbsp; &nbsp; print('\nTime elapsed:', time.time() - start_time)

<br>ì–‘ìí™” ê³µë¶€<br>
ì–‘ìí™” : ì‹¤ìˆ˜í˜• ë³€ìˆ˜(floating-point type)ë¥¼ ì •ìˆ˜í˜• ë³€ìˆ˜(integer or fixed point)ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •<br>
ì–‘ìí™” í•˜ëŠ” ì´ìœ  : ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì— í° ë¹„íŠ¸ìˆ˜ì˜ ìë£Œí˜•ì„ ì‚¬ìš© -&gt; í•™ìŠµ ê³¼ì •ì—ì„œ ê³„ì‚°ëŸ‰ê³¼ í•„ìš”í•œ ë©”ëª¨ë¦¬ í¬ê¸° ë“±ì´ ì»¤ì§€ê²Œ ë¨. -&gt; í•™ìŠµì„ ì‹œí‚¤ê¸° ìœ„í•´ ë§ì€ ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•´ì§€ê³ , ì¶”ë¡ ë„ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë¬¸ì œê°€ ë°œìƒ. ì–‘ìí™”ë¥¼ í†µí•˜ì—¬ íš¨ê³¼ì ì¸ ëª¨ë¸ ìµœì í™”ë¥¼ í•  ìˆ˜ ìˆëŠ”ë°, float íƒ€ì…ì„ intí˜•ìœ¼ë¡œ ì¤„ì´ë©´ì„œ ìš©ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆê³  bit ìˆ˜ë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ê³„ì‚° ë³µì¡ë„ë„ ì¤„ì¼ ìˆ˜ ìˆìŒ<br>
Pipeline<br>
-HuggingFaceì˜ ê°€ì¥ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ, ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…, inference(ì¶”ë¡ )ì„ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤.<br>
-(hugging faceì— ëŒ€í•œ ë‚´ìš©ì€ ì²˜ìŒ ë³´ë‚¸ ì½”ë© íŒŒì¼ ê°€ì¥ ìœ„ì— ìˆìœ¼ë‹ˆ ë” ì•Œì•„ë³´ê³ ì‹¶ìœ¼ì‹œë©´ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤!)<br>
-pretrained model(ì‚¬ì „í•™ìŠµ ëª¨ë¸)ì„ ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ì‰¬ìš´ ë°©ë²•.<br>
-ì‚¬ì „í•™ìŠµëª¨ë¸ì´ë€ : ì˜ˆë¥¼ ë“¤ì–´ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œ, ê°ì • ë¶„ì„ ë¬¸ì œë¥¼ í•™ìŠµí–ˆë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•. ì¦‰, ê°ì • ë¶„ì„ ë¬¸ì œë¥¼ í•™ìŠµí•˜ë©´ì„œ ì–»ì€ ì–¸ì–´ì— ëŒ€í•œ ì´í•´ë¥¼ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¬¸ì œë¥¼ í•™ìŠµí•˜ëŠ” ë° í™œìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤.<br>
pipeline(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, kwargs) ë§¤ê°œë³€ìˆ˜ ì„¤ëª…**<br>
-task : ì–´ë–¤ ì‘ì—…ì„ í• ê²ƒì¸ê°€? -&gt; ì—¬ê¸°ì—ì„œëŠ” 'text-generation' í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—…ì„ í• ê±°ì„. ( ê·¸ ì™¸ question-answering, translation ë“±ë“±ì´ ìˆìŒ ) ì´ê±´ pipelineì„ ì‚¬ìš©í•  ë•Œ ê¼­ ì§€ì •í•´ì£¼ì–´ì•¼ í•¨. ë‚˜ë¨¸ì§€ê²ƒë“¤ì€ ê¸°ë³¸ìœ¼ë¡œ ì§€ì •ëœ ê²ƒë“¤ì´ ìˆê¸° ë•Œë¬¸ì— ë”°ë¡œ í•„ìš”í•œ ê²½ìš°ë§Œ ì§€ì •í•´ì£¼ë©´ ë¨.<br>
-model : ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í• ê²ƒì¸ê°€? -&gt; ì—¬ê¸°ì—ì„œëŠ” "meta-llama/Meta-Llama-3-8B-Instruct" ë¼ëŠ” hugging faceì—ì„œ ë¯¸ë¦¬ ê°€ì ¸ì˜¨ ëª¨ë¸ì„ ì‚¬ìš©.<br>
-device map : ëª¨ë¸ì´ ì–´ë””ì„œ(GPU ë˜ëŠ” CPU) ì‹¤í–‰ë˜ì–´ì•¼í• ê¹Œ? -&gt; ì—¬ê¸°ì—ì„œëŠ” "auto" ë¡œ, í˜„ì¬ ê¸°ê¸°ì—ì„œ ì‚¬ìš©ê°€ëŠ¥í•œ ì¥ì†Œë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³ , GPUê°€ ìˆë‹¤ë©´ ì´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©<br>
-model_kwargs : ì¶”ê°€ë¡œ ì „ë‹¬í•  ë§¤ê°œë³€ìˆ˜(ì˜ˆë¥¼ ë“¤ì–´ íŠ¹ì • ì„¤ì •ì„ ë³€ê²½í•˜ëŠ” ê²½ìš° ì‚¬ìš©) -&gt; ì—¬ê¸°ì—ì„œëŠ” {"quantization_config": quantization_config} ì´ë¼ëŠ” quantization(ì–‘ìí™”) ì— ëŒ€í•œ ì„¤ì •ì„ í¬í•¨í•˜êµ¬ ìˆìŒ.<br>#ì¤€ë¹„
!pip install bitsandbytes # ì–‘ìí™” ê¸°ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒŒì´ì¬ ëª¨ë“ˆ ë‹¤ìš´ë¡œë“œ
!pip install -U bitsandbytes
from transformers import pipeline, BitsAndBytesConfig # BitsAndBytesConfig í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì–‘ìí™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

  

#í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸("meta-llama/Meta-Llama-3-8B-Instruct"ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•¨)
from huggingface_hub import login
login("ë‚´ TOKEN")

  

#ì–‘ìí™” ì˜µì…˜ ì„¤ì •
#4bitë¡œ ë˜ì–´ìˆê¸´ í•˜ì§€ë§Œ, 8bitë„ ê°€ëŠ¥.

quantization_config = BitsAndBytesConfig(load_in_4bit=True) &nbsp;# You can also try load_in_8bit
pipe = pipeline("text-generation", "meta-llama/Meta-Llama-3-8B-Instruct", device_map="auto", model_kwargs={"quantization_config": quantization_config})



#ì–‘ìí™” í•œ í›„ ì‹¤í–‰
chat = [
&nbsp; &nbsp; {"role": "system", "content": "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986."},
&nbsp; &nbsp; {"role": "user", "content": "Hey, can you tell me any fun things to do in New York?"}
]
response = pipe(chat, max_new_tokens=512)
print(response[0]['generated_text'][-1]['content'])
chat.append(
&nbsp; &nbsp; {"role": "user", "content": "Wait, what's so wild about soup cans?"}
)
response = pipe(chat, max_new_tokens=512)
print(response[0]['generated_text'][-1]['content'])

]]></description><link>https://ejkiwi.github.io/2024_ì—¬ë¦„_ëª¨ê°ì½”/20240813-ëª¨ê°ì½”-í™œë™-7íšŒì°¨.html</link><guid isPermaLink="false">2024_ì—¬ë¦„_ëª¨ê°ì½”/20240813 ëª¨ê°ì½” í™œë™ 7íšŒì°¨.md</guid><pubDate>Wed, 25 Sep 2024 07:11:10 GMT</pubDate></item></channel></rss>