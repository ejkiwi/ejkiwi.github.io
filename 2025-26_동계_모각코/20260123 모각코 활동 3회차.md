SimcCLR논문 읽기.

시각적 표현의 대조 학습을 위한 간단한 프레임워크

[https://arxiv.org/pdf/2002.05709](https://arxiv.org/pdf/2002.05709)

자기지도학습 - 라벨 없이도 좋은 이미지 표현을 학습하기위한 방법들 중 한 방식으로서 나온 아이디어

같은 이미지를 두 번 다르게 변형
같은 이미지에서 나온 두 버전 → 비슷하게
다른 이미지에서 나온 두 버전 → 다르게

초록 분석
*“This paper presents SimCLR: a simple framework for contrastive learning of visual representations.” 이 논문은 SimCLR을 제안합니다: 시각적 표현의 대조 학습을 위한 간단한 프레임워크*
`#SimCLR #contrastivelearning #simple `
논문의 contribution은 “간단하면서도 효과적인” 방법!

*“We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank.” 우리는 최근 제안된 대조 자기지도학습 알고리즘들을 단순화했으며, 특수한 구조나 메모리 뱅크가 필요없습니다.*
기존 방법의 문제점 지적 ∙ Specialized architectures: 특별히 설계된 복잡한 네트워크 ∙ Memory bank: 이전 데이터를 저장하는 큰 메모리 (MoCo, InstDisc 등이 사용) - 이전에 계산한 feature들을 저장해두는 큰 저장소. 메모리 많이 먹고 구현 복잡함 ∙ SimCLR은 이런 거 없이도 잘 된다란 말임

*“In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework.” 대조 예측 과제가 유용한 표현을 학습하게 만드는 요인을 이해하기 위해, 우리는 프레임워크의 주요 구성 요소들을 체계적으로 연구했습니다.* 
∙ 이 논문의 방법론적 기여… 단순히 “이게 잘 되더라”가 아니라 → “왜 잘 되는지“ 분석
∙ “systematically study” = Ablation study (소거 실험)를 많이 했다는 뜻 → 이 논문의 강점! 각 구성요소의 영향을 실험으로 증명 ( Ablation study : )

*“We show that (1) composition of data augmentations plays a critical role…, (2) introducing a learnable nonlinear transformation… substantially improves…, and (3) contrastive learning benefits from larger batch sizes and more training steps…” 
우리는 다음을 보였습니다:*
*1. 데이터 증강의 조합이 중요한 역할을 함*
*2. 학습 가능한 비선형 변환을 도입하면 성능이 크게 향상됨*
*3. 대조 학습은 큰 배치 크기와 더 많은 학습 단계로부터 이득을 봄*
이 논문의 핵심 기여 3가지를 미리 요약! 발견 (1): 데이터 증강 ∙ “composition” = 여러 개를 조합하는 것 ∙ Critical role = 매우 중요함 ∙ 특히 crop + color distortion 조합 발견 (2): Projection head ∙ “nonlinear transformation” = MLP (비선형 신경망) ∙ “between representation and loss” = 표현 h와 손실 함수 사이에 삽입 ∙ Substantially improves = 엄청 좋아짐 (실제로 10%+ 향상) 발견 (3): 학습 설정 ∙ Larger batch sizes = 4096 이상 ∙ More training steps = 1000 epochs ∙ “compared to supervised learning” = 지도학습보다 더 필요함

*“By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet.” 이러한 발견들을 결합하여, 우리는 ImageNet에서 자기지도학습과 준지도학습에 대한 이전 방법들을 크게 능가할 수 있었습니다. 평가 데이터셋 ImageNet (가장 널리 쓰이는 벤치마크)으로 두 가지 세팅에서 테스트: ∙ Self-supervised: 라벨 전혀 안 씀 ∙ Semi-supervised: 라벨 조금만 씀 (1%, 10%)*
(구체적 성능) “A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50.” SimCLR이 학습한 자기지도 표현에 선형 분류기를 학습시키면 76.5% top-1 정확도를 달성하며, 이는 이전 최고 성능 대비 7% 상대적 향상이고, 지도학습 ResNet-50의 성능과 동등합니다. Linear evaluation 학습된 feature를 고정 (freeze)하고 그 위에 간단한 선형 분류기만 학습하는건데 Feature의 품질을 측정하는 표준 방법임 ∙ “matching supervised ResNet-50” ∙ 엄청난 의미! 라벨 없이도 지도학습과 같은 성능!

(Semi-supervised 성능) “When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100× fewer labels.” 한글: 라벨의 1%만으로 fine-tuning 했을 때, 우리는 85.8% top-5 정확도를 달성하며, 이는 100배 적은 라벨로 AlexNet을 능가합니다. ∙ 1% labels = ImageNet의 1%만 라벨 사용 ∙ Top-5 accuracy = 상위 5개 예측 중 정답이 있으면 맞음 ∙ AlexNet: 100% 라벨 필요 ∙ SimCLR: 1% 라벨로 더 좋은 성능 ∙ 라벨링 비용을 100배 줄일 수 있다! 왜 AlexNet과 비교? ∙ AlexNet은 2012년 ImageNet 우승 모델이어가지고 딥러닝 역사에서 중요한 baseline이엇음.