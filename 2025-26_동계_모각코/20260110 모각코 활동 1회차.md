
오늘의 목표 : 기존 작성 코드 분석하고 내가 뭘 해야할지 생각해보기

## 1 데이터 처리 (CIFAR10 Dataset)

|                       |                          |
| --------------------- | ------------------------ |
| 데이터 타입                | 설명                       |
| LABELED_TRAIN         | 레이블이 있는 학습 데이터 (전체의 10%) |
| UNLABELED_TRAIN       | 레이블이 없는 학습 데이터 (전체의 90%) |
| VALID/UNLABELED_VALID | 검증 데이터 (전체의 10%)         |
| TEST                  | 테스트 데이터                  |

핵심 특징:
- Unlabeled 데이터의 경우 각 이미지를 0°, 90°, 180°, 270° 회전하여 4배로 증강
- 회전 각도(0-3)를 레이블로 사용하여 Pretext Task 학습
- Labeled/Unlabeled 데이터 분할을 위한 캐싱 메커니즘으로 구현함

## 2 모델 구조 (Model)

백본 (Backbone):
- ResNet-18 기반
- CIFAR-10에 맞게 첫 번째 Conv 레이어 수정 (kernel_size=3, stride=1)
- MaxPool 레이어 제거
- 512차원 임베딩 출력

분류기 (Classifiers):
- classifier: Downstream task용 10-way 분류기 (CIFAR-10 클래스)
- rotation_classifier: Pretext task용 4-way 분류기 (회전 각도)

동작 방식:
- is_pretext 플래그에 따라 사용할 분류기 결정
- 체크포인트에서 가중치 로드 기능 제공 (from_checkpoint)

## 3 학습 절차 (Trainer)

주요 기능:
- _train_one_epoch: 1 에포크 학습 수행
- _evaluate: 검증/테스트 데이터로 평가
- train: 전체 학습 루프 (early stopping, checkpoint 관리)
- test: 최종 테스트 수행

체크포인트 관리:
- 검증 손실 기준으로 상위 K개 모델 저장 (save_top_k)
- Early stopping (patience 파라미터)
- 학습 진행 상황을 tqdm으로 시각화

## 4. 학습 파이프라인

### 4.1 지도학습 (Supervised Learning)
1. Labeled 데이터 (10%)만 사용
2. 50 에포크 학습, learning rate = 1e-3
3. CIFAR-10 클래스 직접 예측

### 4.2 자기지도학습 (Self-Supervised Learning)
A. Pretext Task (회전 예측)
4. Unlabeled 데이터 (90%) 사용
5. 30 에포크 학습, learning rate = 1e-3
6. 이미지 회전 각도(0°, 90°, 180°, 270°) 예측
7. 백본 네트워크가 시각적 표현 학습

B. Downstream Task (분류)
8. Pretext에서 학습한 백본 사용
9. Labeled 데이터 (10%)로 Fine-tuning
10. 30 에포크 학습, learning rate = 1e-4
11. CIFAR-10 클래스 예측

## 5. 제 생각은요

### 5.1 장점
- 명확한 구조: 데이터, 모델, 학습이 잘 분리되어 있음
- 재사용 가능하게 함 : Dataset과 Trainer 클래스가 일반화되어 있음
- 효율적인 데이터 관리: 데이터 분할 일관성 보장
- 실용적인 기능: 체크포인트 관리, early stopping, 진행 상황 시각화

### 5.2 개선이 필요한 부분

|        |                                         |                                                        |
| ------ | --------------------------------------- | ------------------------------------------------------ |
| 영역     | 문제점                                     | 개선 방향                                                  |
| 코드 구조  | 단일 노트북에 모든 코드가 집중되어 있음                  | 모듈 단위로 분리해봐도 갠찮을듯 (dataset.py, model.py, trainer.py 등) |
| 설정 관리  | 하드코딩된 하이퍼파라미터 (learning rate, epochs 등) | config.yaml 또는 argparse로 관리해보기?                        |
| 확장성    | Rotation 방법만 구현되어 있음                    | 다양한 SSL 방법론을 쉽게 추가할 수 있는 구조                            |
| 실험 추적  | 실험 결과를 체계적으로 기록하는 기능 부재                 | TensorBoard 또는 WandB 라는 것이 있다고 한다. 이걸 추가해보는것은 어떨까      |
| 데이터 증강 | 기본 전처리만 사용 (Resize, Normalize)          | RandomCrop, ColorJitter 등 추가 증강 기법                     |
| 성능 최적화 | Learning rate scheduler 미사용             | CosineAnnealingLR, WarmUp 등 적용해보기                      |
| 평가 지표  | Loss와 Accuracy만 추적                      | Precision, Recall, F1-score 등 추가                       |

  
## 6. 다음 단계 계획 (2회차)

### 6.1 코드 리팩토링 목표
12. 모듈화: dataset, model, trainer를 별도 파일로 분리
13. 설정 파일: config.yaml 생성 및 적용
14. 프로젝트 구조: src/, configs/, experiments/ 디렉토리 구성
15. 데이터 증강: transform pipeline 개선
16. 학습 안정화: learning rate scheduler 추가

## 7. 결론
아직 확장성과 유지보수성 측면에서 개선의 여지가 있어보인다! 2회차에서는 코드를 모듈화하고 설정 관리를 체계화하여 더 나은 구조로 발전시켜보면 좋을 거 같다.
이를 통해 앞으로 SimCLR, MAE 등 다양한 자기지도학습 방법론을 쉽게 추가하고 비교 실험할 수 있는 기반을 마련하는것이 내 목표이당
